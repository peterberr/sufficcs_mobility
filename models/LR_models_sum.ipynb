{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading summary for  Berlin\n",
      "loading summary for  Paris\n",
      "loading summary for  France_other\n",
      "loading summary for  Germany_other\n"
     ]
    }
   ],
   "source": [
    "# extra code to summarise and combine mean results for all cities, car ownership\n",
    "cities2=['Berlin','Paris','France_other','Germany_other']\n",
    "\n",
    "parameters=['IncomeDetailed_Numeric', 'HHSize','maxAgeHH','UniversityEducation',\n",
    "            'HHType_simp[T.MultiAdult_Kids]','HHType_simp[T.Single_Female]','HHType_simp[T.Single_Male]','HHType_simp[T.Single_Parent]',\n",
    "            'DistCenter','DistSubcenter','UrbPopDensity','UrbBuildDensity','IntersecDensity',\n",
    "            'StreetLength','bike_lane_share','LU_UrbFab','LU_Comm']\n",
    "\n",
    "for city in cities2:\n",
    "    print('loading summary for ', city)\n",
    "    summ_city=pd.read_csv('../outputs/ML_Results/carown_LR/' + city + '_mean.csv')\n",
    "    summ_city['city']=city\n",
    "    summ_city_short=summ_city.copy()\n",
    "    summ_city_short.loc[summ_city_short['param'].isin(['bike_lane_share','LU_UrbFab','LU_Comm']),'coefficient']=0.01*summ_city_short.loc[summ_city_short['param'].isin(['bike_lane_share','LU_UrbFab','LU_Comm']),'coefficient']\n",
    "    summ_city_short.loc[summ_city_short['p']>0.1,'coefficient']=np.nan\n",
    "    summ_city_short.index=summ_city_short.param\n",
    "    summ_city_short=summ_city_short.reindex(parameters)\n",
    "    summ_city_short.reset_index(drop=True,inplace=True)\n",
    "    if city==cities2[0]:\n",
    "        summ_all=summ_city_short.copy()\n",
    "    else:\n",
    "        summ_all=pd.concat([summ_all,summ_city_short])\n",
    "\n",
    "l2= [summ_all.columns[0:3].to_list()] \n",
    "cols = ['city'] + [i for sl in l2 for i in sl]\n",
    "summ_all=summ_all.loc[:,cols].copy()\n",
    "\n",
    "summ_all.to_csv('../outputs/ML_Results/carown_LR/All_short.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading summary for  Berlin\n",
      "loading summary for  Paris\n",
      "loading summary for  Madrid\n",
      "loading summary for  Wien\n",
      "loading summary for  France_other\n",
      "loading summary for  Germany_other\n"
     ]
    }
   ],
   "source": [
    "# extra code to summarise and combine mean results for all cities, aggregate distance\n",
    "cities2=['Berlin','Paris','Madrid','Wien','France_other','Germany_other']\n",
    "\n",
    "parameters=['Age','Commute_Trip',\n",
    "            'DistCenter_res','DistSubcenter_res','UrbPopDensity_res','UrbBuildDensity_res','IntersecDensity_res',\n",
    "            'street_length_res','bike_lane_share_res','LU_UrbFab_res','LU_Comm_res']\n",
    "\n",
    "for city in cities2:\n",
    "    print('loading summary for ', city)\n",
    "    summ_city=pd.read_csv('../outputs/ML_Results/dist_LR/' + city + '_mean.csv')\n",
    "    summ_city['city']=city\n",
    "    summ_city_short=summ_city.copy()\n",
    "    summ_city_short.loc[summ_city_short['param'].isin(['bike_lane_share_res','LU_UrbFab_res','LU_Comm_res']),'coefficient']=0.01*summ_city_short.loc[summ_city_short['param'].isin(['bike_lane_share_res','LU_UrbFab_res','LU_Comm_res']),'coefficient']\n",
    "    summ_city_short.loc[summ_city_short['p']>0.1,'coefficient']=np.nan\n",
    "    summ_city_short.index=summ_city_short.param\n",
    "    summ_city_short=summ_city_short.reindex(parameters)\n",
    "    summ_city_short.reset_index(drop=True,inplace=True)\n",
    "    if city==cities2[0]:\n",
    "        summ_all=summ_city_short.copy()\n",
    "    else:\n",
    "        summ_all=pd.concat([summ_all,summ_city_short])\n",
    "\n",
    "l2= [summ_all.columns[0:3].to_list()] \n",
    "cols = ['city'] + [i for sl in l2 for i in sl]\n",
    "summ_all=summ_all.loc[:,cols].copy()\n",
    "\n",
    "summ_all.to_csv('../outputs/ML_Results/dist_LR/All_short.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading summary for  Berlin\n",
      "loading summary for  Paris\n",
      "loading summary for  Madrid\n",
      "loading summary for  Wien\n",
      "loading summary for  France_other\n",
      "loading summary for  Germany_other\n"
     ]
    }
   ],
   "source": [
    "# extra code to summarise and combine mean results for all cities, mode choice\n",
    "cities=['Berlin','Paris','Madrid','Wien','France_other','Germany_other']\n",
    "\n",
    "parameters=['Sex','Age','CarAvailable','Trip_Distance',\n",
    "            'Trip_Purpose_Agg[T.Home↔Leisure]','Trip_Purpose_Agg[T.Home↔School]','Trip_Purpose_Agg[T.Home↔Shopping]','Trip_Purpose_Agg[T.Home↔Work]','Trip_Purpose_Agg[T.Other]',\n",
    "            'DistCenter_origin','DistSubcenter_origin','UrbPopDensity_origin','UrbBuildDensity_origin','IntersecDensity_origin',\n",
    "            'street_length_origin','bike_lane_share_origin','LU_UrbFab_origin','LU_Comm_origin']\n",
    "\n",
    "for city in cities:\n",
    "    print('loading summary for ', city)\n",
    "    summ_city=pd.read_csv('../outputs/ML_Results/mode_MNLR/' + city + '_mean.csv')\n",
    "    summ_city['city']=city\n",
    "    summ_city_short=summ_city.loc[summ_city['param'].isin(parameters),:].copy().reset_index(drop=True)\n",
    "    summ_city_short.loc[summ_city_short['param'].isin(['bike_lane_share_origin','LU_UrbFab_origin','LU_Comm_origin']),'bike']=0.01*summ_city_short.loc[summ_city_short['param'].isin(['bike_lane_share_origin','LU_UrbFab_origin','LU_Comm_origin']),'bike']\n",
    "    summ_city_short.loc[summ_city_short['param'].isin(['bike_lane_share_origin','LU_UrbFab_origin','LU_Comm_origin']),'walk']=0.01*summ_city_short.loc[summ_city_short['param'].isin(['bike_lane_share_origin','LU_UrbFab_origin','LU_Comm_origin']),'walk']\n",
    "    summ_city_short.loc[summ_city_short['param'].isin(['bike_lane_share_origin','LU_UrbFab_origin','LU_Comm_origin']),'transit']=0.01*summ_city_short.loc[summ_city_short['param'].isin(['bike_lane_share_origin','LU_UrbFab_origin','LU_Comm_origin']),'transit']\n",
    "    summ_city_short.loc[summ_city_short['bike_p']>0.1,'bike']=np.nan\n",
    "    summ_city_short.loc[summ_city_short['walk_p']>0.1,'walk']=np.nan\n",
    "    summ_city_short.loc[summ_city_short['transit_p']>0.1,'transit']=np.nan\n",
    "    summ_city_short.index=summ_city_short.param\n",
    "    summ_city_short=summ_city_short.reindex(parameters)\n",
    "    summ_city_short.reset_index(drop=True,inplace=True)\n",
    "    if city==cities[0]:\n",
    "        summ_all=summ_city_short.copy()\n",
    "    else:\n",
    "        summ_all=pd.concat([summ_all,summ_city_short])\n",
    "\n",
    "l2= [summ_all.columns[0:7].to_list()] \n",
    "cols = ['city'] + [i for sl in l2 for i in sl]\n",
    "summ_all=summ_all.loc[:,cols].copy()\n",
    "\n",
    "summ_all.to_csv('../outputs/ML_Results/mode_MNLR/All_short.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading summary for  Berlin\n",
      "loading summary for  Paris\n",
      "loading summary for  Madrid\n",
      "loading summary for  Wien\n",
      "loading summary for  France_other\n",
      "loading summary for  Germany_other\n"
     ]
    }
   ],
   "source": [
    "# extra code to summarise and combine mean results for all cities, detailed commute distance\n",
    "cities2=['Berlin','Paris','Madrid','Wien','France_other','Germany_other']\n",
    "\n",
    "parameters=['Sex','Age','Education[T.Secondary]','Education[T.University]','Education[T.Unknown/Other]','HHSize',\n",
    "            'DistCenter_res','DistSubcenter_res','UrbPopDensity_res','UrbBuildDensity_res','IntersecDensity_res',\n",
    "            'street_length_res','bike_lane_share_res','LU_UrbFab_res','LU_Comm_res']\n",
    "\n",
    "for city in cities2:\n",
    "    print('loading summary for ', city)\n",
    "    summ_city=pd.read_csv('../outputs/ML_Results/dist_commute/' + city + '_mean.csv')\n",
    "    summ_city['city']=city\n",
    "    summ_city_short=summ_city.copy()\n",
    "    summ_city_short.loc[summ_city_short['param'].isin(['bike_lane_share_res','LU_UrbFab_res','LU_Comm_res']),'coefficient']=0.01*summ_city_short.loc[summ_city_short['param'].isin(['bike_lane_share_res','LU_UrbFab_res','LU_Comm_res']),'coefficient']\n",
    "    summ_city_short.loc[summ_city_short['p']>0.1,'coefficient']=np.nan\n",
    "    summ_city_short.index=summ_city_short.param\n",
    "    summ_city_short=summ_city_short.reindex(parameters)\n",
    "    summ_city_short.reset_index(drop=True,inplace=True)\n",
    "    if city==cities2[0]:\n",
    "        summ_all=summ_city_short.copy()\n",
    "    else:\n",
    "        summ_all=pd.concat([summ_all,summ_city_short])\n",
    "\n",
    "l2= [summ_all.columns[0:3].to_list()] \n",
    "cols = ['city'] + [i for sl in l2 for i in sl]\n",
    "summ_all=summ_all.loc[:,cols].copy()\n",
    "\n",
    "summ_all.to_csv('../outputs/ML_Results/dist_commute/All_short.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "city_mob_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
