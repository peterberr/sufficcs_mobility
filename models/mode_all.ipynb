{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    }
   ],
   "source": [
    "# load in required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shap\n",
    "import re\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, cross_validate, GroupKFold, StratifiedGroupKFold, RepeatedKFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics, linear_model\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import statsmodels.formula.api as smf\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "cities_all=['Berlin','Dresden','Düsseldorf','Frankfurt am Main','Kassel','Leipzig','Magdeburg','Potsdam','Clermont','Dijon','Lille','Lyon','Montpellier','Nantes','Nimes','Paris','Toulouse','Madrid','Wien','France_other','Germany_other']\n",
    "countries=['Germany','Germany','Germany','Germany','Germany','Germany','Germany','Germany','France','France','France','France','France','France','France','France','France','Spain','Austria','France','Germany']\n",
    "#form_str=\"Mode_num ~ FeatureM_Trip_Time + FeatureM_Season + FeatureM_Trip_Purpose_Agg + FeatureM_Sex + FeatureM_Age + FeatureM_Trip_Distance + FeatureM_CarOwnershipHH + FeatureM_HHSize + FeatureM_Occupation +  FeatureM_Education  + FeatureM_UrbPopDensity_origin +  FeatureM_DistSubcenter_origin + FeatureM_DistCenter_origin +  FeatureM_UrbBuildDensity_origin +  FeatureM_IntersecDensity_origin +  FeatureM_street_length_origin +FeatureM_bike_lane_share_origin +  FeatureM_LU_UrbFab_origin + FeatureM_LU_Comm_origin + FeatureM_transit_accessibility_origin + FeatureM_Country\" # FeatureM_CarAvailable replaced by FeatureM_CarOwnershipHH\n",
    "form_str=\"Mode_num ~ FeatureM_Trip_Time + FeatureM_Season + FeatureM_Trip_Purpose_Agg + FeatureM_Sex + FeatureM_Age + FeatureM_Trip_Distance + FeatureM_CarOwnershipHH + FeatureM_HHSize + FeatureM_Occupation +  FeatureM_Education  + FeatureM_UrbPopDensity_res +  FeatureM_DistSubcenter_res + FeatureM_DistCenter_res +  FeatureM_UrbBuildDensity_res +  FeatureM_IntersecDensity_res +  FeatureM_street_length_res +FeatureM_bike_lane_share_res +  FeatureM_LU_UrbFab_res + FeatureM_LU_Comm_res + FeatureM_transit_accessibility_res + FeatureM_Country\" # FeatureM_CarAvailable replaced by FeatureM_CarOwnershipHH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 columns in the data for  Berlin\n",
      "Dresden\n",
      "77 columns in the data for  Dresden\n",
      "Dresden added.\n",
      "126573 rows in the combined dataframe\n",
      "Leipzig\n",
      "77 columns in the data for  Leipzig\n",
      "Leipzig added.\n",
      "138169 rows in the combined dataframe\n",
      "Magdeburg\n",
      "77 columns in the data for  Magdeburg\n",
      "Magdeburg added.\n",
      "147545 rows in the combined dataframe\n",
      "Potsdam\n",
      "77 columns in the data for  Potsdam\n",
      "Potsdam added.\n",
      "153368 rows in the combined dataframe\n",
      "Frankfurt am Main\n",
      "77 columns in the data for  Frankfurt am Main\n",
      "Frankfurt am Main added.\n",
      "159403 rows in the combined dataframe\n",
      "Düsseldorf\n",
      "77 columns in the data for  Düsseldorf\n",
      "Düsseldorf added.\n",
      "183247 rows in the combined dataframe\n",
      "Kassel\n",
      "77 columns in the data for  Kassel\n",
      "Kassel added.\n",
      "192614 rows in the combined dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 columns in the data for  Clermont\n",
      "Toulouse\n",
      "58 columns in the data for  Toulouse\n",
      "Toulouse added.\n",
      "49864 rows in the combined dataframe\n",
      "Montpellier\n",
      "58 columns in the data for  Montpellier\n",
      "Montpellier added.\n",
      "80127 rows in the combined dataframe\n",
      "Lyon\n",
      "58 columns in the data for  Lyon\n",
      "Lyon added.\n",
      "132884 rows in the combined dataframe\n",
      "Nantes\n",
      "58 columns in the data for  Nantes\n",
      "Nantes added.\n",
      "167926 rows in the combined dataframe\n",
      "Nimes\n",
      "58 columns in the data for  Nimes\n",
      "Nimes added.\n",
      "179143 rows in the combined dataframe\n",
      "Lille\n",
      "58 columns in the data for  Lille\n",
      "Lille added.\n",
      "215992 rows in the combined dataframe\n",
      "Dijon\n",
      "58 columns in the data for  Dijon\n",
      "Dijon added.\n",
      "230246 rows in the combined dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Columns (46) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "city0='Berlin'\n",
    "df0=pd.read_csv('../outputs/Combined/' + city0 + '_UF.csv')\n",
    "print(len(df0.columns), 'columns in the data for ', city0)\n",
    "df0['City']=city0\n",
    "df_all=df0.copy()\n",
    "\n",
    "cities=['Dresden','Leipzig','Magdeburg','Potsdam','Frankfurt am Main','Düsseldorf','Kassel']\n",
    "for city1 in cities:\n",
    "    print(city1)\n",
    "    df1=pd.read_csv('../outputs/Combined/' + city1 + '_UF.csv')\n",
    "    print(len(df1.columns), 'columns in the data for ', city1)\n",
    "    df1['City']=city1\n",
    "    if len(df1.columns==df_all.columns):\n",
    "        df_all=pd.concat([df_all,df1])\n",
    "        print(city1, 'added.')\n",
    "        print(len(df_all), 'rows in the combined dataframe')\n",
    "df_all['HHNR']=df_all['City']+'_'+df_all['HHNR'].astype(int).astype(str)\n",
    "df_all['HH_PNR']=df_all['City']+'_'+df_all['HH_PNR'].astype(int).astype(str)\n",
    "df_all['HH_P_WNR']=df_all['City']+'_'+df_all['HH_P_WNR'].astype(int).astype(str)\n",
    "df_DE=df_all.copy()\n",
    "df_DE['Start']=df_DE['trip_type_all'].str[:4]\n",
    "df_DE=df_DE.loc[df_DE['Start']=='Home',]\n",
    "df_DE['Country']='Germany'\n",
    "\n",
    "df_DE=df_DE.loc[:,('City', 'HH_P_WNR','HH_PNR', 'HHNR','Ori_geocode', 'Des_geocode','Res_geocode',#'Dist_group', # IDs, trip geocodes, home-Res_geocode\n",
    "    'Trip_Time', 'Season','Trip_Purpose_Agg','CarOwnershipHH', 'Trip_Distance', # trip details, keep number of accompanying householders now as 'TravelAlone', but remove n_others_car as it gives away the mode.     \n",
    "    'HHSize', #'IncomeDetailed_Numeric', #'IncomeDetailed', 'HHType', # household details\n",
    "    'Sex',  'Occupation', 'Education','Age', # 'MobilityConstraints',\n",
    "    'UrbPopDensity_res','DistSubcenter_res', 'DistCenter_res','UrbBuildDensity_res',# 'MeanTime2Transit_res',\n",
    "    'IntersecDensity_res', 'street_length_res','bike_lane_share_res', 'transit_accessibility_res',# 'diff', 'K_avg_res', 'StreetDensity_res', 'StreetsPerNode_res', 'K_avg_dest','StreetDensity_dest', 'StreetsPerNode_dest', \n",
    "    'LU_UrbFab_res','LU_Comm_res','Country',# urban form features, land-use features are now all from UA. removed 'LU_Road_res', 'LU_Road_dest',\n",
    "    # target: mode\n",
    "    'Mode')\n",
    "    ]\n",
    "city0='Clermont'\n",
    "df0=pd.read_csv('../outputs/Combined/' + city0 + '_UF.csv')\n",
    "df0.drop(columns=['IncomeDetailed', 'IncomeHarmonised','Des_Sec_Zone', 'Month', 'Ori_Sec_Zone','Res_Sec_Zone', 'Sample','Sector_Zone', 'Zone','geo_unit','N_Stops', 'N_Legs'],errors='ignore',inplace=True)\n",
    "print(len(df0.columns), 'columns in the data for ', city0)\n",
    "df0['City']=city0\n",
    "df_all=df0.copy()\n",
    "\n",
    "cities=['Toulouse','Montpellier','Lyon','Nantes','Nimes','Lille','Dijon']\n",
    "for city1 in cities:\n",
    "    print(city1)\n",
    "    df1=pd.read_csv('../outputs/Combined/' + city1 + '_UF.csv')\n",
    "    df1.drop(columns=['IncomeDetailed', 'IncomeHarmonised', 'Des_Sec_Zone', 'Month', 'Ori_Sec_Zone','Res_Sec_Zone',  'Sample','Sector_Zone', 'Zone','geo_unit',\n",
    "                    'Commune', 'Des_Cell', 'Grid_Cell', 'NoMobilityConstraints','Ori_Cell','N_Stops', 'N_Legs'],errors='ignore',inplace=True) # plus spme non-shared Paris variables\n",
    "    print(len(df1.columns), 'columns in the data for ', city1)\n",
    "    df1['City']=city1\n",
    "    if len(df1.columns==df_all.columns):\n",
    "        df1=df1[df_all.columns] # this is required for Paris, where the same columns exist after the dropping above, but the order is different\n",
    "        df_all=pd.concat([df_all,df1])\n",
    "        print(city1, 'added.')\n",
    "        print(len(df_all), 'rows in the combined dataframe')\n",
    "df_all['HHNR']=df_all['City']+'_'+df_all['HHNR'].astype(str)\n",
    "df_all['HH_PNR']=df_all['City']+'_'+df_all['HH_PNR'].astype(str)\n",
    "df_all['HH_P_WNR']=df_all['City']+'_'+df_all['HH_P_WNR'].astype(str)\n",
    "df_FR=df_all.copy()\n",
    "df_FR['Start']=df_FR['trip_type_all'].str[:4]\n",
    "df_FR=df_FR.loc[df_FR['Start']=='Home',]\n",
    "df_FR['Country']='France'\n",
    "df_FR=df_FR.loc[:,('City','HH_P_WNR','HH_PNR', 'HHNR','Ori_geocode', 'Des_geocode','Res_geocode',#'Dist_group', # IDs, trip geocodes, home-Res_geocode\n",
    "    'Trip_Time', 'Season','Trip_Purpose_Agg','CarOwnershipHH', 'Trip_Distance', # trip details, keep number of accompanying householders now as 'TravelAlone', but remove n_others_car as it gives away the mode.     \n",
    "    'HHSize', #'IncomeDetailed_Numeric', #'IncomeDetailed', 'HHType', # household details\n",
    "    'Sex',  'Occupation', 'Education','Age', # 'MobilityConstraints',\n",
    "    'UrbPopDensity_res','DistSubcenter_res', 'DistCenter_res','UrbBuildDensity_res',# 'MeanTime2Transit_res',\n",
    "    'IntersecDensity_res', 'street_length_res','bike_lane_share_res','transit_accessibility_res', # 'diff', 'K_avg_res', 'StreetDensity_res', 'StreetsPerNode_res', 'K_avg_dest','StreetDensity_dest', 'StreetsPerNode_dest', \n",
    "    'LU_UrbFab_res','LU_Comm_res', 'Country',  # urban form features, land-use features are now all from UA. removed 'LU_Road_res', 'LU_Road_dest',\n",
    "    # target: mode\n",
    "    'Mode')\n",
    "    ]\n",
    "city='Paris'\n",
    "df=pd.read_csv('../outputs/Combined/' + city + '_UF.csv')\n",
    "df['City']=city\n",
    "df['Country']='France'\n",
    "df['HHNR']=df['City']+'_'+df['HHNR'].astype(str)\n",
    "df['HH_PNR']=df['City']+'_'+df['HH_PNR'].astype(str)\n",
    "df['HH_P_WNR']=df['City']+'_'+df['HH_P_WNR'].astype(str)\n",
    "df['Start']=df['trip_type_all'].str[:4]\n",
    "df=df.loc[df['Start']=='Home',]\n",
    "\n",
    "df_Paris=df.copy()\n",
    "df_Paris=df_Paris.loc[:,('City','HH_P_WNR','HH_PNR', 'HHNR','Ori_geocode', 'Des_geocode','Res_geocode',#'Dist_group', # IDs, trip geocodes, home-Res_geocode\n",
    "    'Trip_Time', 'Season','Trip_Purpose_Agg','CarOwnershipHH', 'Trip_Distance', # trip details, keep number of accompanying householders now as 'TravelAlone', but remove n_others_car as it gives away the mode.     \n",
    "    'HHSize', #'IncomeDetailed_Numeric', #'IncomeDetailed', 'HHType', # household details\n",
    "    'Sex',  'Occupation', 'Education','Age', # 'MobilityConstraints',\n",
    "    'UrbPopDensity_res','DistSubcenter_res', 'DistCenter_res','UrbBuildDensity_res',# 'MeanTime2Transit_res',\n",
    "    'IntersecDensity_res', 'street_length_res','bike_lane_share_res','transit_accessibility_res', # 'diff', 'K_avg_res', 'StreetDensity_res', 'StreetsPerNode_res', 'K_avg_dest','StreetDensity_dest', 'StreetsPerNode_dest', \n",
    "    'LU_UrbFab_res','LU_Comm_res', 'Country',  # urban form features, land-use features are now all from UA. removed 'LU_Road_res', 'LU_Road_dest',\n",
    "    # target: mode\n",
    "    'Mode')\n",
    "    ]\n",
    "city='Madrid'\n",
    "df=pd.read_csv('../outputs/Combined/' + city + '_UF.csv')\n",
    "df['City']=city\n",
    "df['Country']='Spain'\n",
    "df['HHNR']=df['City']+'_'+df['HHNR'].astype(str)\n",
    "df['HH_PNR']=df['City']+'_'+df['HH_PNR'].astype(str)\n",
    "df['HH_P_WNR']=df['City']+'_'+df['HH_P_WNR'].astype(str)\n",
    "df['Start']=df['trip_type_all'].str[:4]\n",
    "df=df.loc[df['Start']=='Home',]\n",
    "\n",
    "df_Madrid=df.copy()\n",
    "df_Madrid=df_Madrid.loc[:,('City','HH_P_WNR','HH_PNR', 'HHNR','Ori_geocode', 'Des_geocode','Res_geocode',#'Dist_group', # IDs, trip geocodes, home-Res_geocode\n",
    "    'Trip_Time', 'Season','Trip_Purpose_Agg','CarOwnershipHH', 'Trip_Distance', # trip details, keep number of accompanying householders now as 'TravelAlone', but remove n_others_car as it gives away the mode.     \n",
    "    'HHSize', #'IncomeDetailed_Numeric', #'IncomeDetailed', 'HHType', # household details\n",
    "    'Sex',  'Occupation', 'Education','Age', # 'MobilityConstraints',\n",
    "    'UrbPopDensity_res','DistSubcenter_res', 'DistCenter_res','UrbBuildDensity_res',# 'MeanTime2Transit_res',\n",
    "    'IntersecDensity_res', 'street_length_res','bike_lane_share_res','transit_accessibility_res', # 'diff', 'K_avg_res', 'StreetDensity_res', 'StreetsPerNode_res', 'K_avg_dest','StreetDensity_dest', 'StreetsPerNode_dest', \n",
    "    'LU_UrbFab_res','LU_Comm_res','Country',   # urban form features, land-use features are now all from UA. removed 'LU_Road_res', 'LU_Road_dest',\n",
    "    # target: mode\n",
    "    'Mode')\n",
    "    ]\n",
    "city='Wien'\n",
    "df=pd.read_csv('../outputs/Combined/' + city + '_UF.csv')\n",
    "df['City']=city\n",
    "df['Country']='Austria'\n",
    "df['HHNR']=df['City']+'_'+df['HHNR'].astype(str)\n",
    "df['HH_PNR']=df['City']+'_'+df['HH_PNR'].astype(str)\n",
    "df['HH_P_WNR']=df['City']+'_'+df['HH_P_WNR'].astype(str)\n",
    "df['Start']=df['trip_type_all'].str[:4]\n",
    "df=df.loc[df['Start']=='Home',]\n",
    "\n",
    "df_Wien=df.copy()\n",
    "df_Wien=df_Wien.loc[:,('City','HH_P_WNR','HH_PNR', 'HHNR','Ori_geocode', 'Des_geocode','Res_geocode',#'Dist_group', # IDs, trip geocodes, home-Res_geocode\n",
    "    'Trip_Time', 'Season','Trip_Purpose_Agg','CarOwnershipHH', 'Trip_Distance', # trip details, keep number of accompanying householders now as 'TravelAlone', but remove n_others_car as it gives away the mode.     \n",
    "    'HHSize', #'IncomeDetailed_Numeric', #'IncomeDetailed', 'HHType', # household details\n",
    "    'Sex',  'Occupation', 'Education','Age', # 'MobilityConstraints',\n",
    "    'UrbPopDensity_res','DistSubcenter_res', 'DistCenter_res','UrbBuildDensity_res',# 'MeanTime2Transit_res',\n",
    "    'IntersecDensity_res', 'street_length_res','bike_lane_share_res','transit_accessibility_res', # 'diff', 'K_avg_res', 'StreetDensity_res', 'StreetsPerNode_res', 'K_avg_dest','StreetDensity_dest', 'StreetsPerNode_dest', \n",
    "    'LU_UrbFab_res','LU_Comm_res','Country',   # urban form features, land-use features are now all from UA. removed 'LU_Road_res', 'LU_Road_dest',\n",
    "    # target: mode\n",
    "    'Mode')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>HH_P_WNR</th>\n",
       "      <th>HH_PNR</th>\n",
       "      <th>HHNR</th>\n",
       "      <th>Ori_geocode</th>\n",
       "      <th>Des_geocode</th>\n",
       "      <th>Res_geocode</th>\n",
       "      <th>Trip_Time</th>\n",
       "      <th>Season</th>\n",
       "      <th>Trip_Purpose_Agg</th>\n",
       "      <th>...</th>\n",
       "      <th>DistCenter_res</th>\n",
       "      <th>UrbBuildDensity_res</th>\n",
       "      <th>IntersecDensity_res</th>\n",
       "      <th>street_length_res</th>\n",
       "      <th>bike_lane_share_res</th>\n",
       "      <th>transit_accessibility_res</th>\n",
       "      <th>LU_UrbFab_res</th>\n",
       "      <th>LU_Comm_res</th>\n",
       "      <th>Country</th>\n",
       "      <th>Mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>Berlin_10295611</td>\n",
       "      <td>Berlin_1029561</td>\n",
       "      <td>Berlin_102956</td>\n",
       "      <td>10115</td>\n",
       "      <td>10115</td>\n",
       "      <td>10115</td>\n",
       "      <td>Daytime Off-Peak</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Home↔Work</td>\n",
       "      <td>...</td>\n",
       "      <td>1.972959</td>\n",
       "      <td>9.010181e+06</td>\n",
       "      <td>39.380867</td>\n",
       "      <td>127.710059</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>6.381020e+03</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>0.366144</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>Berlin_10296411</td>\n",
       "      <td>Berlin_1029641</td>\n",
       "      <td>Berlin_102964</td>\n",
       "      <td>10115</td>\n",
       "      <td>10245</td>\n",
       "      <td>10115</td>\n",
       "      <td>AM_Rush</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Home↔Work</td>\n",
       "      <td>...</td>\n",
       "      <td>1.972959</td>\n",
       "      <td>9.010181e+06</td>\n",
       "      <td>39.380867</td>\n",
       "      <td>127.710059</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>6.381020e+03</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>0.366144</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>Berlin_10296421</td>\n",
       "      <td>Berlin_1029642</td>\n",
       "      <td>Berlin_102964</td>\n",
       "      <td>10115</td>\n",
       "      <td>10178</td>\n",
       "      <td>10115</td>\n",
       "      <td>Daytime Off-Peak</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Home↔Work</td>\n",
       "      <td>...</td>\n",
       "      <td>1.972959</td>\n",
       "      <td>9.010181e+06</td>\n",
       "      <td>39.380867</td>\n",
       "      <td>127.710059</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>6.381020e+03</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>0.366144</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>Berlin_10296431</td>\n",
       "      <td>Berlin_1029643</td>\n",
       "      <td>Berlin_102964</td>\n",
       "      <td>10115</td>\n",
       "      <td>10119</td>\n",
       "      <td>10115</td>\n",
       "      <td>AM_Rush</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Home↔School</td>\n",
       "      <td>...</td>\n",
       "      <td>1.972959</td>\n",
       "      <td>9.010181e+06</td>\n",
       "      <td>39.380867</td>\n",
       "      <td>127.710059</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>6.381020e+03</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>0.366144</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>Berlin_10296433</td>\n",
       "      <td>Berlin_1029643</td>\n",
       "      <td>Berlin_102964</td>\n",
       "      <td>10115</td>\n",
       "      <td>10179</td>\n",
       "      <td>10115</td>\n",
       "      <td>PM Rush</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Home↔Leisure</td>\n",
       "      <td>...</td>\n",
       "      <td>1.972959</td>\n",
       "      <td>9.010181e+06</td>\n",
       "      <td>39.380867</td>\n",
       "      <td>127.710059</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>6.381020e+03</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>0.366144</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277493</th>\n",
       "      <td>Wien</td>\n",
       "      <td>Wien_9066_4_1</td>\n",
       "      <td>Wien_9066_4</td>\n",
       "      <td>Wien_9066</td>\n",
       "      <td>31701</td>\n",
       "      <td>91701</td>\n",
       "      <td>31701</td>\n",
       "      <td>AM_Rush</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Home↔School</td>\n",
       "      <td>...</td>\n",
       "      <td>13.787251</td>\n",
       "      <td>4.250415e+03</td>\n",
       "      <td>6.937562</td>\n",
       "      <td>135.293102</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.419321e-11</td>\n",
       "      <td>0.038474</td>\n",
       "      <td>0.023820</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277494</th>\n",
       "      <td>Wien</td>\n",
       "      <td>Wien_15603_1_1</td>\n",
       "      <td>Wien_15603_1</td>\n",
       "      <td>Wien_15603</td>\n",
       "      <td>31701</td>\n",
       "      <td>30735</td>\n",
       "      <td>31701</td>\n",
       "      <td>AM_Rush</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Home↔Shopping</td>\n",
       "      <td>...</td>\n",
       "      <td>13.787251</td>\n",
       "      <td>4.250415e+03</td>\n",
       "      <td>6.937562</td>\n",
       "      <td>135.293102</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.419321e-11</td>\n",
       "      <td>0.038474</td>\n",
       "      <td>0.023820</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277495</th>\n",
       "      <td>Wien</td>\n",
       "      <td>Wien_15603_2_1</td>\n",
       "      <td>Wien_15603_2</td>\n",
       "      <td>Wien_15603</td>\n",
       "      <td>31701</td>\n",
       "      <td>30735</td>\n",
       "      <td>31701</td>\n",
       "      <td>AM_Rush</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Home↔Shopping</td>\n",
       "      <td>...</td>\n",
       "      <td>13.787251</td>\n",
       "      <td>4.250415e+03</td>\n",
       "      <td>6.937562</td>\n",
       "      <td>135.293102</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.419321e-11</td>\n",
       "      <td>0.038474</td>\n",
       "      <td>0.023820</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277496</th>\n",
       "      <td>Wien</td>\n",
       "      <td>Wien_10149_1_1</td>\n",
       "      <td>Wien_10149_1</td>\n",
       "      <td>Wien_10149</td>\n",
       "      <td>31711</td>\n",
       "      <td>31723</td>\n",
       "      <td>31711</td>\n",
       "      <td>AM_Rush</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Home↔Companion</td>\n",
       "      <td>...</td>\n",
       "      <td>10.429480</td>\n",
       "      <td>2.350708e+03</td>\n",
       "      <td>23.465284</td>\n",
       "      <td>132.376026</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>5.084280e+00</td>\n",
       "      <td>0.090456</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277497</th>\n",
       "      <td>Wien</td>\n",
       "      <td>Wien_10149_2_1</td>\n",
       "      <td>Wien_10149_2</td>\n",
       "      <td>Wien_10149</td>\n",
       "      <td>31711</td>\n",
       "      <td>92001</td>\n",
       "      <td>31711</td>\n",
       "      <td>AM_Rush</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Home↔Work</td>\n",
       "      <td>...</td>\n",
       "      <td>10.429480</td>\n",
       "      <td>2.350708e+03</td>\n",
       "      <td>23.465284</td>\n",
       "      <td>132.376026</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>5.084280e+00</td>\n",
       "      <td>0.090456</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277498 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          City         HH_P_WNR          HH_PNR           HHNR Ori_geocode  \\\n",
       "0       Berlin  Berlin_10295611  Berlin_1029561  Berlin_102956       10115   \n",
       "1       Berlin  Berlin_10296411  Berlin_1029641  Berlin_102964       10115   \n",
       "2       Berlin  Berlin_10296421  Berlin_1029642  Berlin_102964       10115   \n",
       "3       Berlin  Berlin_10296431  Berlin_1029643  Berlin_102964       10115   \n",
       "4       Berlin  Berlin_10296433  Berlin_1029643  Berlin_102964       10115   \n",
       "...        ...              ...             ...            ...         ...   \n",
       "277493    Wien    Wien_9066_4_1     Wien_9066_4      Wien_9066       31701   \n",
       "277494    Wien   Wien_15603_1_1    Wien_15603_1     Wien_15603       31701   \n",
       "277495    Wien   Wien_15603_2_1    Wien_15603_2     Wien_15603       31701   \n",
       "277496    Wien   Wien_10149_1_1    Wien_10149_1     Wien_10149       31711   \n",
       "277497    Wien   Wien_10149_2_1    Wien_10149_2     Wien_10149       31711   \n",
       "\n",
       "       Des_geocode Res_geocode         Trip_Time  Season Trip_Purpose_Agg  \\\n",
       "0            10115       10115  Daytime Off-Peak  Spring        Home↔Work   \n",
       "1            10245       10115           AM_Rush  Winter        Home↔Work   \n",
       "2            10178       10115  Daytime Off-Peak  Winter        Home↔Work   \n",
       "3            10119       10115           AM_Rush  Winter      Home↔School   \n",
       "4            10179       10115           PM Rush  Winter     Home↔Leisure   \n",
       "...            ...         ...               ...     ...              ...   \n",
       "277493       91701       31701           AM_Rush  Autumn      Home↔School   \n",
       "277494       30735       31701           AM_Rush  Autumn    Home↔Shopping   \n",
       "277495       30735       31701           AM_Rush  Autumn    Home↔Shopping   \n",
       "277496       31723       31711           AM_Rush  Autumn   Home↔Companion   \n",
       "277497       92001       31711           AM_Rush  Autumn        Home↔Work   \n",
       "\n",
       "        ...  DistCenter_res  UrbBuildDensity_res  IntersecDensity_res  \\\n",
       "0       ...        1.972959         9.010181e+06            39.380867   \n",
       "1       ...        1.972959         9.010181e+06            39.380867   \n",
       "2       ...        1.972959         9.010181e+06            39.380867   \n",
       "3       ...        1.972959         9.010181e+06            39.380867   \n",
       "4       ...        1.972959         9.010181e+06            39.380867   \n",
       "...     ...             ...                  ...                  ...   \n",
       "277493  ...       13.787251         4.250415e+03             6.937562   \n",
       "277494  ...       13.787251         4.250415e+03             6.937562   \n",
       "277495  ...       13.787251         4.250415e+03             6.937562   \n",
       "277496  ...       10.429480         2.350708e+03            23.465284   \n",
       "277497  ...       10.429480         2.350708e+03            23.465284   \n",
       "\n",
       "        street_length_res bike_lane_share_res transit_accessibility_res  \\\n",
       "0              127.710059              0.0965              6.381020e+03   \n",
       "1              127.710059              0.0965              6.381020e+03   \n",
       "2              127.710059              0.0965              6.381020e+03   \n",
       "3              127.710059              0.0965              6.381020e+03   \n",
       "4              127.710059              0.0965              6.381020e+03   \n",
       "...                   ...                 ...                       ...   \n",
       "277493         135.293102              0.0000              3.419321e-11   \n",
       "277494         135.293102              0.0000              3.419321e-11   \n",
       "277495         135.293102              0.0000              3.419321e-11   \n",
       "277496         132.376026              0.0113              5.084280e+00   \n",
       "277497         132.376026              0.0113              5.084280e+00   \n",
       "\n",
       "        LU_UrbFab_res  LU_Comm_res  Country     Mode  \n",
       "0            0.395459     0.366144  Germany  Transit  \n",
       "1            0.395459     0.366144  Germany     Bike  \n",
       "2            0.395459     0.366144  Germany     Bike  \n",
       "3            0.395459     0.366144  Germany     Bike  \n",
       "4            0.395459     0.366144  Germany  Transit  \n",
       "...               ...          ...      ...      ...  \n",
       "277493       0.038474     0.023820  Austria  Transit  \n",
       "277494       0.038474     0.023820  Austria      Car  \n",
       "277495       0.038474     0.023820  Austria      Car  \n",
       "277496       0.090456     0.039216  Austria      Car  \n",
       "277497       0.090456     0.039216  Austria      Car  \n",
       "\n",
       "[277498 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.concat([df_DE,df_FR,df_Paris,df_Madrid,df_Wien],ignore_index=True)\n",
    "\n",
    "Occ_dict={'Employed_FullTime':'Employed','Employed_PartTime':'Employed','Employed':'Employed','Trainee':'Employed',\n",
    "          'Student_School':'Student_School','Student_3rdLevel':'Student_3rdLevel','Pre-School':'Pre-School','Retired':'Retired',\n",
    "          'Unemployed':'Unemployed/Other','Other':'Unemployed/Other','Home_Partner':'Unemployed/Other'}\n",
    "Edu_dict={'University':'University','Secondary':'Secondary','Secondary+BAC':'Secondary','Secondary+Matura':'Secondary',\n",
    "          'Apprenticeship':'Apprenticeship',\n",
    "          'Elementary':'Primary/None','Pre-School':'Primary/None','No diploma yet':'Primary/None','Unknown':'Primary/None','Other':'Primary/None'}\n",
    "\n",
    "df['Occupation']=df['Occupation'].map(Occ_dict)\n",
    "df['Education']=df['Education'].map(Edu_dict)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  columns with value below zero\n"
     ]
    }
   ],
   "source": [
    "df['Mode_num']=0\n",
    "# car, bike, foot, transit\n",
    "df.loc[df['Mode']=='Car','Mode_num']=0\n",
    "df.loc[df['Mode']=='Bike','Mode_num']=1\n",
    "df.loc[df['Mode']=='Foot','Mode_num']=2\n",
    "df.loc[df['Mode']=='Transit','Mode_num']=3\n",
    "\n",
    "df.drop(columns='Mode',inplace=True)\n",
    "# identify the feature columns\n",
    "N_non_feature=7 # how many non-features are at the start of the df\n",
    "cols=df.columns\n",
    "newcols=(df.columns[:N_non_feature].tolist()) + ('FeatureM' +'_'+ cols[N_non_feature:-1]).tolist() + (df.columns[-1:].tolist())\n",
    "# change column names\n",
    "df.set_axis(newcols,axis=1,inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df.dropna(inplace=True)\n",
    "df0=df.copy()\n",
    "\n",
    "# convert  all categorical variables to dummies\n",
    "df_Cat=df.select_dtypes('object')[[col for col in df.select_dtypes('object').columns if \"FeatureM\" in col]]\n",
    "for col in df_Cat:\n",
    "    dum=pd.get_dummies(df[[col]])\n",
    "    df = pd.concat([df, dum], axis = 1)\n",
    "    # remove the original categorical columns\n",
    "df.drop(df_Cat.columns.tolist(),axis=1,inplace=True)\n",
    "# HPO with full dataset, grouping by individual person\n",
    "target = 'Mode_num'\n",
    "N=len(df)\n",
    "\n",
    "# Define the parameter space to be considered\n",
    "PS = {\"learning_rate\": [0.1 ,0.2,0.3], \n",
    "                \"n_estimators\": [100, 250,400],\n",
    "                \"max_depth\":[4, 5]}\n",
    "\n",
    "X=df[[col for col in df.columns if \"FeatureM\" in col]]\n",
    "y = df[target]\n",
    "\n",
    "tf=(X < 0).all(0)\n",
    "print(len(tf[tf]),' columns with value below zero')\n",
    "if len(tf[tf])>0:\n",
    "    print(tf[tf].index.values)\n",
    "    raise Exception(\"Some columns have values below zero\")\n",
    "\n",
    "gr=df['HH_PNR']\n",
    "groups=gr\n",
    "gkf = list(GroupKFold(n_splits=9).split(X,y,groups)) # i found somewhere online that i had to define the cv splitter as a list, can't find the source at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "city='All'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "form_str=\"Mode_num ~ FeatureM_Trip_Time + FeatureM_Season + FeatureM_Trip_Purpose_Agg + FeatureM_Sex + FeatureM_Age + FeatureM_Trip_Distance + FeatureM_CarOwnershipHH + FeatureM_HHSize + FeatureM_Occupation +  FeatureM_Education  + FeatureM_UrbPopDensity_res +  FeatureM_DistSubcenter_res + FeatureM_DistCenter_res +  FeatureM_UrbBuildDensity_res +  FeatureM_IntersecDensity_res +  FeatureM_street_length_res +FeatureM_bike_lane_share_res +  FeatureM_LU_UrbFab_res + FeatureM_LU_Comm_res + FeatureM_transit_accessibility_res + FeatureM_Country\" # FeatureM_CarAvailable replaced by FeatureM_CarOwnershipHH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPs already identified\n",
      "id 10079093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:27:10] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.735428\n",
      "         Iterations 9\n",
      "id 20039238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:20] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.735436\n",
      "         Iterations 9\n",
      "id 31792903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:33:32] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.736489\n",
      "         Iterations 9\n",
      "id 21049432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:37:21] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.734539\n",
      "         Iterations 9\n",
      "id 49007969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:41:49] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.734444\n",
      "         Iterations 9\n",
      "id 45554951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:46:46] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.735054\n",
      "         Iterations 9\n",
      "id 09162328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:51:10] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.734328\n",
      "         Iterations 9\n",
      "id 49929052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:55:50] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.735964\n",
      "         Iterations 9\n",
      "id 41729473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:59:42] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.734938\n",
      "         Iterations 9\n",
      "Model f1: All\n",
      "0.7578684585058834\n"
     ]
    }
   ],
   "source": [
    "fp='../outputs/ML_Results/'+city+'_HPO_mode_common_new_summary.csv'\n",
    "if os.path.isfile(fp):\n",
    "    print('HPs already identified')\n",
    "    HPO_summary=pd.read_csv(fp)\n",
    "    n_parameter_all = HPO_summary['N_est'][0]\n",
    "    lr_parameter_all = HPO_summary['LR'][0]\n",
    "    md_parameter_all = HPO_summary['MD'][0]\n",
    "else:\n",
    "    # define grid search cross validator\n",
    "    tuning_all = GridSearchCV(estimator=XGBClassifier(verbosity=0,use_label_encoder=False), param_grid=PS, cv=gkf, scoring=\"f1_weighted\",return_train_score=True)\n",
    "    tuning_all.fit(X,y)\n",
    "\n",
    "    print('best hyper-parameters identified by HPO')\n",
    "    print(tuning_all.best_params_)\n",
    "    print('model score with best hyper-paramteres')\n",
    "    print(tuning_all.best_score_)\n",
    "    cv_res_all=tuning_all.cv_results_\n",
    "\n",
    "    n_parameter_all = tuning_all.best_params_['n_estimators']\n",
    "    lr_parameter_all = tuning_all.best_params_['learning_rate']\n",
    "    md_parameter_all = tuning_all.best_params_['max_depth']\n",
    "\n",
    "    # save results of HPO\n",
    "    r8=['gkf_gridSearch','full','9splits_hhperGroups',tuning_all.best_params_['learning_rate'],tuning_all.best_params_['max_depth'],tuning_all.best_params_['n_estimators'],round(tuning_all.best_score_,3),round(cv_res_all['std_test_score'][tuning_all.best_index_],3),N] #\n",
    "    # also include other results lists here if HPO is done for more than one cv type or sample\n",
    "    HPO_summary=pd.DataFrame([r8],columns=['CV_Type','Sample','CV_params','LR','MD','N_est','F1_best','SD_best','N_obs']) # the last element in this case is the sd of f1 scores in the fold which produced best results\n",
    "\n",
    "# now redo the CV and calculate the SHAP values with the best HPs\n",
    "cv = GroupKFold(n_splits=9)\n",
    "\n",
    "y_predict = pd.DataFrame()\n",
    "y_predict2 = pd.DataFrame()\n",
    "y_test = pd.DataFrame()\n",
    "y_test2 = pd.DataFrame()\n",
    "\n",
    "shap_values0= pd.DataFrame()\n",
    "shap_values1= pd.DataFrame()\n",
    "shap_values2= pd.DataFrame()\n",
    "shap_values3= pd.DataFrame()\n",
    "\n",
    "summ_table_list=[]\n",
    "\n",
    "model = XGBClassifier(\n",
    "    max_depth=md_parameter_all, \n",
    "    n_estimators=n_parameter_all, \n",
    "    learning_rate=lr_parameter_all)\n",
    "\n",
    "# model2 = LogisticRegression()\n",
    "writer = pd.ExcelWriter('../outputs/ML_Results/mode_MNLR_new/'  + city + '.xlsx', engine='openpyxl')\n",
    "for train_idx, test_idx in cv.split(X,groups=gr): # select here \n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test_fold = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    df_train, df_test = df0.iloc[train_idx], df0.iloc[test_idx]\n",
    "    #id=test_idx[0].astype(str)\n",
    "    id=datetime.now().strftime(\"%S%f\")\n",
    "    print('id',id)\n",
    "\n",
    "    # train & predict\n",
    "    model.fit(X_train, y_train, verbose=False, eval_set=[(X_train, y_train), (X_test, y_test_fold)])\n",
    "    y_predict_fold = pd.Series(model.predict(X_test), index=X_test.index)\n",
    "\n",
    "    # explain\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values_fold = explainer.shap_values(X_test)\n",
    "\n",
    "    shap_values_fold0=shap_values_fold[0]\n",
    "    shap_values_fold1=shap_values_fold[1]\n",
    "    shap_values_fold2=shap_values_fold[2]\n",
    "    shap_values_fold3=shap_values_fold[3]\n",
    "    \n",
    "    shap_values_fold0 = pd.DataFrame(shap_values_fold0, index=X_test.index, columns=X.columns)\n",
    "    shap_values_fold1 = pd.DataFrame(shap_values_fold1, index=X_test.index, columns=X.columns)\n",
    "    shap_values_fold2 = pd.DataFrame(shap_values_fold2, index=X_test.index, columns=X.columns)\n",
    "    shap_values_fold3 = pd.DataFrame(shap_values_fold3, index=X_test.index, columns=X.columns)    \n",
    "\n",
    "    y_predict = pd.concat([y_predict, y_predict_fold], axis=0)\n",
    "    y_test = pd.concat([y_test, y_test_fold], axis=0)\n",
    "\n",
    "    shap_values0 = pd.concat([shap_values0, shap_values_fold0], axis=0)\n",
    "    shap_values1 = pd.concat([shap_values1, shap_values_fold1], axis=0)\n",
    "    shap_values2 = pd.concat([shap_values2, shap_values_fold2], axis=0)\n",
    "    shap_values3 = pd.concat([shap_values3, shap_values_fold3], axis=0)\n",
    "    \n",
    "    #model2.fit(X_train, y_train)\n",
    "    # y_predict_fold2 = pd.Series(model2.predict(X_test), index=X_test.index)\n",
    "    # y_predict2 = pd.concat([y_predict2, y_predict_fold2], axis=0)\n",
    "    \n",
    "    # X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    # y_train, y_test_fold = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    # df_train, df_test = df.iloc[train_idx], df.iloc[test_idx]\n",
    "    y_test_fold2=df_test['Mode_num']\n",
    "\n",
    "    try:\n",
    "        log_reg = smf.mnlogit(form_str, data=df_train).fit()\n",
    "        yhat=np.asarray(log_reg.predict(df_test.drop(columns='Mode_num'))).argmax(1)\n",
    "        y_predict_fold2 = pd.Series(yhat, index=df_test.index)\n",
    "        y_predict2 = pd.concat([y_predict2, y_predict_fold2], axis=0)\n",
    "        y_test2 = pd.concat([y_test2, y_test_fold2], axis=0)\n",
    "\n",
    "        coeff=log_reg.params.reset_index()\n",
    "        coeff.rename(columns={'index':'param',0:'bike',1:'walk',2:'transit'},inplace=True)\n",
    "        coeff.head()\n",
    "        pval=log_reg.pvalues.reset_index()\n",
    "        pval.rename(columns={'index':'param',0:'bike_p',1:'walk_p',2:'transit_p'},inplace=True)\n",
    "        pval.head()\n",
    "        summ_table=pd.concat([coeff,pval.loc[:,['bike_p','walk_p','transit_p']]],axis=1)\n",
    "        summ_table['param']=summ_table['param'].str.replace('FeatureM_','')\n",
    "\n",
    "        st_list_fold=[summ_table.drop(columns='param').to_numpy()]\n",
    "        summ_table_list.append(st_list_fold)\n",
    "        #summ_table.head()\n",
    "\n",
    "        summ_table.to_excel(writer, sheet_name='summ' + id,index=False)\n",
    "    except: \n",
    "        print('Logit Model Error')\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()\n",
    "writer.close()\n",
    "\n",
    "mdarray=np.array(summ_table_list).squeeze()\n",
    "means=np.nanmean(mdarray,axis=0)\n",
    "means_df=pd.DataFrame(data=np.hstack((np.reshape(summ_table['param'].to_numpy(),(len(summ_table),1)),means)),columns=summ_table.columns.values)\n",
    "means_df.to_csv('../outputs/ML_Results/mode_MNLR_new/'  + city + '_mean.csv',index=False)\n",
    "\n",
    "y_test = y_test.squeeze(axis=1)\n",
    "y_test2 = y_test2.squeeze(axis=1)\n",
    "y_predict = y_predict.squeeze(axis=1)\n",
    "y_predict2 = y_predict2.squeeze(axis=1)\n",
    "f1_model_ML = metrics.f1_score(y_test, y_predict, average='weighted')\n",
    "f1_model_LR = metrics.f1_score(y_test2, y_predict2, average='weighted')\n",
    "print('Model f1: ' + city)\n",
    "print(f1_model_ML)\n",
    "\n",
    "HPO_summary['F1_full_ML']=f1_model_ML\n",
    "HPO_summary['F1_full_LR']=f1_model_LR\n",
    "HPO_summary['City']=city\n",
    "HPO_summary.to_csv('../outputs/ML_Results/' + city + '_HPO_mode_common_new_summary.csv',index=False)\n",
    "\n",
    "# optionally here, check which variables are more important than random noise, then downselect X to those variables, and go back to HPO (or CV) and run once more from there.\n",
    "\n",
    "shap_valueslist=[shap_values0.sort_index().to_numpy(),shap_values1.sort_index().to_numpy(),shap_values2.sort_index().to_numpy(),shap_values3.sort_index().to_numpy()]\n",
    "X_disp=[re.sub('FeatureM_','', x) for x in X.sort_index().columns]\n",
    "shap_values_abs=abs(shap_valueslist[0])+abs(shap_valueslist[1])+abs(shap_valueslist[2])+abs(shap_valueslist[3])\n",
    "shap_sum = shap_values_abs.mean(axis=0)\n",
    "importance_df = pd.DataFrame([X_disp, shap_sum.tolist()]).T\n",
    "importance_df.columns = ['column_name', 'shap_importance']\n",
    "importance_df = importance_df.sort_values('shap_importance', ascending=False)\n",
    "\n",
    "with open('../outputs/ML_Results/shap/mode_common_new/' + city + '_importance.pkl', 'wb') as g:\n",
    "    pickle.dump(importance_df, g)\n",
    "\n",
    "# shap_mode = shap_disp(shap_valueslist,X.sort_index(), 'Mode Choice ', city)\n",
    "\n",
    "# save shap_values, to enable later re-creation and editing of shap plots\n",
    "with open('../outputs/ML_Results/shap/mode_common_new/' + city + '.pkl', 'wb') as f:\n",
    "    pickle.dump(shap_valueslist, f)\n",
    "\n",
    "shap.summary_plot(shap_valueslist, X.sort_index(),feature_names=X_disp,max_display=16,  class_names=['car','bike','foot','trans'],class_inds='original', show=False)\n",
    "plt.title('Overall Feature Influence Mode Choice ' + city)\n",
    "plt.savefig('../outputs/ML_Results/result_figures/mode_common_new/' + city + '_mode_FI.png',facecolor='w',dpi=65,bbox_inches='tight')\n",
    "plt.close() \n",
    "\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_predict,normalize='true')\n",
    "# note the high confusion between bike/foot trips, and the high number of transit trips labelled as bike or car, and the high number of bike trips labelled as foot or car\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=np.array(['car','bike','foot','trans']))\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix, mode choice, ' + city + '. F1: ' + str(round(f1_model_ML,3)))\n",
    "plt.savefig('../outputs/ML_Results/result_figures/mode_common_new/' + city + '_mode_CM.png',facecolor='w',dpi=65,bbox_inches='tight')\n",
    "plt.close() \n",
    "\n",
    "col_dict= {'DistCenter_res':'Dist. to city center','DistSubcenter_res':'Dist. to subenter', 'UrbPopDensity_res':'Population density','UrbBuildDensity_res':'Built-up density','ParkingAvailable_Dest':'Parking available',\n",
    "    'IntersecDensity_res':'Intersection density','LU_Comm_res':'Commercial area','LU_UrbFab_res':'Urban Fabric area','street_length_res':'Avg. street length','bike_lane_share_res':'Cycle lanes',\n",
    "    'Trip_Purpose_Agg_Home↔Work':'Commute trip', 'Trip_Purpose_Agg_Home↔Companion':'Companion trip', 'TravelAlone':'Solo trip','Trip_Purpose_Agg_Home↔Leisure':'Leisure trip','Trip_Purpose_Agg_Home↔Shopping':'Shopping trip','Trip_Purpose_Agg_Home↔School':'School trip',\n",
    "    'Trip_Time_Evening':'Evening trip','Trip_Time_AM_Rush':'Morning trip','transit_accessibility_res':'Transit accessibility',\n",
    "    'Country_France':'France','Country_Germany':'Germany','Country_Austria':'Austria','Country_Spain':'Spain',\n",
    "    'Season_Winter':'Winter season','MeanTime2Transit_res':'Time to transit', #'diff':'Elevation_diff',\n",
    "    'Trip_Distance':'Trip distance','CarOwnershipHH':'Car ownership','Occupation_Student_School':'School Student',\n",
    "    'Age':'Age','Sex':'Sex','HHSize':'Household size','IncomeDescriptiveNumeric':'Income','IncomeDetailed_Numeric':'Income',\n",
    "    'Education_University':'University education', 'Occupation_Employed_FullTime':'Employed'}\n",
    "\n",
    "X_lab=[*map(col_dict.get, X_disp)]\n",
    "\n",
    "shap_values=shap_valueslist\n",
    "\n",
    "if city not in ['Berlin','Paris','Madrid','Wien','France_other','Germany_other']:\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(11,8))\n",
    "    ax1 = plt.subplot(221)\n",
    "    shap.summary_plot(shap_values[2], X, feature_names=X_lab, max_display=8, plot_size=None, show=False)\n",
    "    plt.title('Main Feature Influences for Foot Trips ' + city)\n",
    "    plt.xlabel(\"SHAP value\", size=11)\n",
    "    ax2 = plt.subplot(222)\n",
    "    shap.summary_plot(shap_values[1], X, feature_names=X_lab, max_display=8, plot_size=None, show=False)\n",
    "    plt.title('Main Feature Influences for Bike Trips ' + city)\n",
    "    plt.xlabel(\"SHAP value\", size=11)\n",
    "    ax3 = plt.subplot(223)\n",
    "    shap.summary_plot(shap_values[0], X, feature_names=X_lab, max_display=8, plot_size=None, show=False)\n",
    "    plt.title('Main Feature Influences for Car Trips ' + city)\n",
    "    plt.xlabel(\"SHAP value\", size=11)\n",
    "    ax3 = plt.subplot(224)\n",
    "    shap.summary_plot(shap_values[3], X, feature_names=X_lab, max_display=8, plot_size=None, show=False)\n",
    "    plt.title('Main Feature Influences for Transit Trips ' + city)\n",
    "    plt.xlabel(\"SHAP value\", size=11)\n",
    "    plt.savefig('../outputs/ML_Results/result_figures/mode_common_new/' + city + '_FI_all.png',facecolor='w',dpi=65,bbox_inches='tight')\n",
    "    plt.close() \n",
    "\n",
    "\n",
    "X_lab=[*map(col_dict.get, X_disp)]\n",
    "if city == 'Berlin': let='a'\n",
    "if city == 'Paris': let='b'\n",
    "if city == 'Madrid': let='c'\n",
    "if city == 'Wien': let='d'\n",
    "if city == 'Germany_other': let='e'\n",
    "if city == 'France_other': let='f'\n",
    "if city == 'All': let='g'\n",
    "\n",
    "if city in ['Berlin','Paris','Madrid','Wien','France_other','Germany_other','All']:\n",
    "    fig, axes = plt.subplots(figsize=(5.5,4))\n",
    "    shap.summary_plot(shap_values[0], X, feature_names=X_lab, max_display=8, plot_size=None, show=False)\n",
    "    plt.title(let + ') ' + city,size=14)\n",
    "    plt.xlabel(\"SHAP (probability of car mode choice)\", size=11)\n",
    "    plt.savefig('../outputs/ML_Results/result_figures/mode_common_new/' + city + '_FI_car.png',facecolor='w',dpi=65,bbox_inches='tight')\n",
    "    plt.close() \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(11,8))\n",
    "    ax1 = plt.subplot(221)\n",
    "    shap.summary_plot(shap_values[2], X, feature_names=X_lab, max_display=8, plot_size=None, show=False)\n",
    "    plt.title(let + ') ' + 'Main Feature Influences for Foot Trips ' + city.replace('_',', '))\n",
    "    plt.xlabel(\"SHAP (probability of foot mode)\", size=11)\n",
    "    ax2 = plt.subplot(222)\n",
    "    shap.summary_plot(shap_values[1], X, feature_names=X_lab, max_display=8, plot_size=None, show=False)\n",
    "    plt.title('Main Feature Influences for Bike Trips ' + city.replace('_',', '))\n",
    "    #plt.title(city.replace('_',', '))\n",
    "    plt.xlabel(\"SHAP (probability of bike mode)\", size=11)\n",
    "    ax3 = plt.subplot(223)\n",
    "    shap.summary_plot(shap_values[0], X, feature_names=X_lab, max_display=8, plot_size=None, show=False)\n",
    "    plt.title('Main Feature Influences for Car Trips ' + city.replace('_',', '))\n",
    "    #plt.title(city.replace('_',', '))\n",
    "    plt.xlabel(\"SHAP (probability of car mode)\", size=11)\n",
    "    ax3 = plt.subplot(224)\n",
    "    shap.summary_plot(shap_values[3], X, feature_names=X_lab, max_display=8, plot_size=None, show=False)\n",
    "    plt.title('Main Feature Influences for Transit Trips ' + city.replace('_',', '))\n",
    "    #plt.title(city.replace('_',', '))\n",
    "    plt.xlabel(\"SHAP (probability of transit mode)\", size=11)\n",
    "\n",
    "    plt.savefig('../outputs/ML_Results/result_figures/mode_common_new/' + city + '_FI_all.png',facecolor='w',dpi=65,bbox_inches='tight')\n",
    "    plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "city_mob_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
