{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    }
   ],
   "source": [
    "# script to model avergage trip distances for commute trips in all cities\n",
    "# last update Peter Berrill Aug 1 2023\n",
    "\n",
    "# load in required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, cross_validate, GroupKFold, StratifiedGroupKFold, RepeatedKFold, StratifiedKFold, GridSearchCV, KFold\n",
    "from sklearn import metrics, linear_model\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import statsmodels.formula.api as smf\n",
    "from datetime import datetime\n",
    "\n",
    "cities_all=['Berlin','Dresden','Düsseldorf','Frankfurt am Main','Kassel','Leipzig','Magdeburg','Potsdam','Clermont','Dijon','Lille','Lyon','Montpellier','Nantes','Nimes','Paris','Toulouse','Madrid','Wien','France_other','Germany_other']\n",
    "countries=['Germany','Germany','Germany','Germany','Germany','Germany','Germany','Germany','France','France','France','France','France','France','France','France','France','Spain','Austria','France','Germany']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berlin Germany\n",
      "Dresden\n",
      "Dresden added.\n",
      "Leipzig\n",
      "Leipzig added.\n",
      "Magdeburg\n",
      "Magdeburg added.\n",
      "Potsdam\n",
      "Potsdam added.\n",
      "Frankfurt am Main\n",
      "Frankfurt am Main added.\n",
      "Düsseldorf\n",
      "Düsseldorf added.\n",
      "Kassel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kassel added.\n"
     ]
    }
   ],
   "source": [
    "city='Berlin'\n",
    "country=countries[cities_all.index(city)]\n",
    "print(city, country)\n",
    "\n",
    "city0='Berlin'\n",
    "df0=pd.read_csv('../outputs/Combined/' + city0 + '_UF.csv')\n",
    "# add to make consistent with definition of apprenticeship within Education in other countries\n",
    "df0.loc[(df0['Training'].isin(['Apprenticeship/Business','Craftsman/Technical'])) & (df0['Education']!='University'),'Education']='Apprenticeship'\n",
    "df0=df0.loc[:,['HH_P_WNR','HH_PNR', 'HHNR','Ori_geocode', 'Des_geocode','Res_geocode', \n",
    "            'Trip_Time', 'Season','Trip_Purpose_Agg','HHSize',\n",
    "            'Sex', 'Occupation', 'Education','Age',\n",
    "            #'PopDensity_res','BuildDensity_res',\n",
    "            'UrbPopDensity_res', 'UrbBuildDensity_res','DistSubcenter_res', 'DistCenter_res',\n",
    "            'IntersecDensity_res', 'street_length_res', 'LU_UrbFab_res','bike_lane_share_res',\n",
    "            'LU_Comm_res' ,'Trip_Distance']]\n",
    "df0['City']=city0\n",
    "df0['Country']='Germany'\n",
    "df_all=df0.copy()\n",
    "\n",
    "cities0=['Dresden', 'Leipzig','Magdeburg','Potsdam','Frankfurt am Main','Düsseldorf','Kassel']\n",
    "for city1 in cities0:\n",
    "        print(city1)\n",
    "        df1=pd.read_csv('../outputs/Combined/' + city1 + '_UF.csv')\n",
    "        df1.loc[(df1['Training'].isin(['Apprenticeship/Business','Craftsman/Technical'])) & (df0['Education']!='University'),'Education']='Apprenticeship'\n",
    "        df1=df1.loc[:,['HH_P_WNR','HH_PNR', 'HHNR','Ori_geocode', 'Des_geocode','Res_geocode', \n",
    "                    'Trip_Time', 'Season','Trip_Purpose_Agg','HHSize',\n",
    "                    'Sex', 'Occupation', 'Education','Age',\n",
    "                    #'PopDensity_res','BuildDensity_res',\n",
    "                    'UrbPopDensity_res', 'UrbBuildDensity_res','DistSubcenter_res', 'DistCenter_res',\n",
    "                    'IntersecDensity_res', 'street_length_res', 'LU_UrbFab_res','bike_lane_share_res',\n",
    "                    'LU_Comm_res','Trip_Distance']]\n",
    "        df1['City']=city1\n",
    "        df1['Country']='Germany'\n",
    "        if len(df1.columns==df_all.columns):\n",
    "                df_all=pd.concat([df_all,df1])\n",
    "                print(city1, 'added.')\n",
    "                #print(len(df_all), 'rows in the combined dataframe')\n",
    "df_all['HHNR']=df_all['City']+'_'+df_all['HHNR'].astype(int).astype(str)\n",
    "df_all['HH_PNR']=df_all['City']+'_'+df_all['HH_PNR'].astype(int).astype(str)\n",
    "df_all['HH_P_WNR']=df_all['City']+'_'+df_all['HH_P_WNR'].astype(str)\n",
    "df_all.drop(columns='City',inplace=True)\n",
    "df_DE=df_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toulouse\n",
      "Toulouse added.\n",
      "Montpellier\n",
      "Montpellier added.\n",
      "Lyon\n",
      "Lyon added.\n",
      "Nantes\n",
      "Nantes added.\n",
      "Nimes\n",
      "Nimes added.\n",
      "Lille\n",
      "Lille added.\n",
      "Dijon\n",
      "Dijon added.\n",
      "Paris\n",
      "Paris added.\n"
     ]
    }
   ],
   "source": [
    "city0='Clermont'\n",
    "df0=pd.read_csv('../outputs/Combined/' + city0 + '_UF.csv')\n",
    "df0=df0.loc[:,['HH_P_WNR','HH_PNR', 'HHNR','Ori_geocode', 'Des_geocode','Res_geocode', \n",
    "            'Trip_Time', 'Season','Trip_Purpose_Agg','HHSize',\n",
    "            'Sex', 'Occupation', 'Education','Age',\n",
    "            #'PopDensity_res','BuildDensity_res',\n",
    "            'UrbPopDensity_res', 'UrbBuildDensity_res','DistSubcenter_res', 'DistCenter_res',\n",
    "            'IntersecDensity_res', 'street_length_res', 'LU_UrbFab_res','bike_lane_share_res',\n",
    "            'LU_Comm_res', 'Trip_Distance']]\n",
    "df0['City']=city0\n",
    "df0['Country']='France'\n",
    "df_all=df0.copy()\n",
    "\n",
    "cities0=['Toulouse','Montpellier','Lyon','Nantes','Nimes','Lille','Dijon','Paris']\n",
    "for city1 in cities0:\n",
    "        print(city1)\n",
    "        df1=pd.read_csv('../outputs/Combined/' + city1 + '_UF.csv')\n",
    "        df1=df1.loc[:,['HH_P_WNR','HH_PNR', 'HHNR','Ori_geocode', 'Des_geocode','Res_geocode', \n",
    "                    'Trip_Time', 'Season','Trip_Purpose_Agg','HHSize',\n",
    "                    'Sex', 'Occupation', 'Education','Age',\n",
    "                    #'PopDensity_res','BuildDensity_res',\n",
    "                    'UrbPopDensity_res', 'UrbBuildDensity_res','DistSubcenter_res', 'DistCenter_res',\n",
    "                    'IntersecDensity_res', 'street_length_res', 'LU_UrbFab_res','bike_lane_share_res',\n",
    "                    'LU_Comm_res', 'Trip_Distance']]\n",
    "        df1['City']=city1\n",
    "        df1['Country']='France'\n",
    "        if len(df1.columns==df_all.columns):\n",
    "                df_all=pd.concat([df_all,df1])\n",
    "                print(city1, 'added.')\n",
    "                #print(len(df_all), 'rows in the combined dataframe')\n",
    "df_all['HHNR']=df_all['City']+'_'+df_all['HHNR'].astype(str)\n",
    "df_all['HH_PNR']=df_all['City']+'_'+df_all['HH_PNR'].astype(str)\n",
    "df_all['HH_P_WNR']=df_all['City']+'_'+df_all['HH_P_WNR'].astype(str)\n",
    "df_all.drop(columns='City',inplace=True)\n",
    "df_FR=df_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../outputs/Combined/' + 'Madrid' + '_UF.csv',dtype={'Ori_geocode': str, 'Des_geocode': str,'Res_geocode': str })\n",
    "df_UF=df.loc[:,['HH_P_WNR','HH_PNR', 'HHNR','Ori_geocode', 'Des_geocode','Res_geocode', \n",
    "                'Trip_Time', 'Season','Trip_Purpose_Agg','HHSize',\n",
    "                'Sex', 'Occupation', 'Education','Age',\n",
    "                #'PopDensity_res','BuildDensity_res',\n",
    "                'UrbPopDensity_res', 'UrbBuildDensity_res','DistSubcenter_res', 'DistCenter_res',\n",
    "                'IntersecDensity_res', 'street_length_res', 'LU_UrbFab_res','bike_lane_share_res',\n",
    "                'LU_Comm_res', 'Trip_Distance']]\n",
    "df_UF['City']='Madrid'\n",
    "df_UF['Country']='Spain'\n",
    "df_UF['HHNR']=df_UF['City']+'_'+df_UF['HHNR'].astype(str)\n",
    "df_UF['HH_PNR']=df_UF['City']+'_'+df_UF['HH_PNR'].astype(str)\n",
    "df_UF['HH_P_WNR']=df_UF['City']+'_'+df_UF['HH_P_WNR'].astype(str)\n",
    "df_UF.drop(columns='City',inplace=True)\n",
    "df_Madrid=df_UF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../outputs/Combined/' + 'Wien' + '_UF.csv',dtype={'Ori_geocode': str, 'Des_geocode': str,'Res_geocode': str })\n",
    "df_UF=df.loc[:,['HH_P_WNR','HH_PNR', 'HHNR','Ori_geocode', 'Des_geocode','Res_geocode', \n",
    "                'Trip_Time', 'Season','Trip_Purpose_Agg','HHSize',\n",
    "                'Sex', 'Occupation', 'Education','Age',\n",
    "                #'PopDensity_res','BuildDensity_res',\n",
    "                'UrbPopDensity_res', 'UrbBuildDensity_res','DistSubcenter_res', 'DistCenter_res',\n",
    "                'IntersecDensity_res', 'street_length_res', 'LU_UrbFab_res','bike_lane_share_res',\n",
    "                'LU_Comm_res', 'Trip_Distance']]\n",
    "df_UF['City']='Wien'\n",
    "df_UF['Country']='Austria'\n",
    "df_UF['HHNR']=df_UF['City']+'_'+df_UF['HHNR'].astype(str)\n",
    "df_UF['HH_PNR']=df_UF['City']+'_'+df_UF['HH_PNR'].astype(str)\n",
    "df_UF['HH_P_WNR']=df_UF['City']+'_'+df_UF['HH_P_WNR'].astype(str)\n",
    "df_UF.drop(columns='City',inplace=True)\n",
    "df_Wien=df_UF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Home↔Leisure      149581\n",
       "Other             120657\n",
       "Home↔Work         120123\n",
       "Home↔Shopping     100382\n",
       "Home↔School        78334\n",
       "Home↔Companion     59846\n",
       "Name: Trip_Purpose_Agg, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_UF=pd.concat([df_DE,df_FR,df_Madrid,df_Wien],ignore_index=True)\n",
    "df_UF['Trip_Purpose_Agg'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HH_P_WNR</th>\n",
       "      <th>HH_PNR</th>\n",
       "      <th>HHNR</th>\n",
       "      <th>Ori_geocode</th>\n",
       "      <th>Des_geocode</th>\n",
       "      <th>Res_geocode</th>\n",
       "      <th>Trip_Time</th>\n",
       "      <th>Season</th>\n",
       "      <th>HHSize</th>\n",
       "      <th>Sex</th>\n",
       "      <th>...</th>\n",
       "      <th>UrbBuildDensity_res</th>\n",
       "      <th>DistSubcenter_res</th>\n",
       "      <th>DistCenter_res</th>\n",
       "      <th>IntersecDensity_res</th>\n",
       "      <th>street_length_res</th>\n",
       "      <th>LU_UrbFab_res</th>\n",
       "      <th>bike_lane_share_res</th>\n",
       "      <th>LU_Comm_res</th>\n",
       "      <th>Country</th>\n",
       "      <th>Trip_Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Berlin_102956_1_1</td>\n",
       "      <td>Berlin_1029561</td>\n",
       "      <td>Berlin_102956</td>\n",
       "      <td>10115</td>\n",
       "      <td>10115</td>\n",
       "      <td>10115</td>\n",
       "      <td>Daytime Off-Peak</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9.010181e+06</td>\n",
       "      <td>2.761334</td>\n",
       "      <td>1.972959</td>\n",
       "      <td>39.380867</td>\n",
       "      <td>127.710059</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.366144</td>\n",
       "      <td>Germany</td>\n",
       "      <td>729.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Berlin_102956_1_2</td>\n",
       "      <td>Berlin_1029561</td>\n",
       "      <td>Berlin_102956</td>\n",
       "      <td>10115</td>\n",
       "      <td>10115</td>\n",
       "      <td>10115</td>\n",
       "      <td>Daytime Off-Peak</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9.010181e+06</td>\n",
       "      <td>2.761334</td>\n",
       "      <td>1.972959</td>\n",
       "      <td>39.380867</td>\n",
       "      <td>127.710059</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.366144</td>\n",
       "      <td>Germany</td>\n",
       "      <td>729.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Berlin_102964_1_1</td>\n",
       "      <td>Berlin_1029641</td>\n",
       "      <td>Berlin_102964</td>\n",
       "      <td>10115</td>\n",
       "      <td>10245</td>\n",
       "      <td>10115</td>\n",
       "      <td>AM_Rush</td>\n",
       "      <td>Winter</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9.010181e+06</td>\n",
       "      <td>2.761334</td>\n",
       "      <td>1.972959</td>\n",
       "      <td>39.380867</td>\n",
       "      <td>127.710059</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.366144</td>\n",
       "      <td>Germany</td>\n",
       "      <td>6259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Berlin_102964_2_1</td>\n",
       "      <td>Berlin_1029642</td>\n",
       "      <td>Berlin_102964</td>\n",
       "      <td>10115</td>\n",
       "      <td>10178</td>\n",
       "      <td>10115</td>\n",
       "      <td>Daytime Off-Peak</td>\n",
       "      <td>Winter</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9.010181e+06</td>\n",
       "      <td>2.761334</td>\n",
       "      <td>1.972959</td>\n",
       "      <td>39.380867</td>\n",
       "      <td>127.710059</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.366144</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1474.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Berlin_102966_2_1</td>\n",
       "      <td>Berlin_1029662</td>\n",
       "      <td>Berlin_102966</td>\n",
       "      <td>10115</td>\n",
       "      <td>10785</td>\n",
       "      <td>10115</td>\n",
       "      <td>AM_Rush</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9.010181e+06</td>\n",
       "      <td>2.761334</td>\n",
       "      <td>1.972959</td>\n",
       "      <td>39.380867</td>\n",
       "      <td>127.710059</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.366144</td>\n",
       "      <td>Germany</td>\n",
       "      <td>4455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628899</th>\n",
       "      <td>Wien_6972_2_4</td>\n",
       "      <td>Wien_6972_2</td>\n",
       "      <td>Wien_6972</td>\n",
       "      <td>91101</td>\n",
       "      <td>31701</td>\n",
       "      <td>31701</td>\n",
       "      <td>Daytime Off-Peak</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4.250415e+03</td>\n",
       "      <td>8.251874</td>\n",
       "      <td>13.787251</td>\n",
       "      <td>6.937562</td>\n",
       "      <td>135.293102</td>\n",
       "      <td>0.038474</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.023820</td>\n",
       "      <td>Austria</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628903</th>\n",
       "      <td>Wien_6972_1_1</td>\n",
       "      <td>Wien_6972_1</td>\n",
       "      <td>Wien_6972</td>\n",
       "      <td>31701</td>\n",
       "      <td>92201</td>\n",
       "      <td>31701</td>\n",
       "      <td>Nighttime Off-Peak</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.250415e+03</td>\n",
       "      <td>8.251874</td>\n",
       "      <td>13.787251</td>\n",
       "      <td>6.937562</td>\n",
       "      <td>135.293102</td>\n",
       "      <td>0.038474</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.023820</td>\n",
       "      <td>Austria</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628904</th>\n",
       "      <td>Wien_6972_2_1</td>\n",
       "      <td>Wien_6972_2</td>\n",
       "      <td>Wien_6972</td>\n",
       "      <td>31701</td>\n",
       "      <td>31719</td>\n",
       "      <td>31701</td>\n",
       "      <td>AM_Rush</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4.250415e+03</td>\n",
       "      <td>8.251874</td>\n",
       "      <td>13.787251</td>\n",
       "      <td>6.937562</td>\n",
       "      <td>135.293102</td>\n",
       "      <td>0.038474</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.023820</td>\n",
       "      <td>Austria</td>\n",
       "      <td>20000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628908</th>\n",
       "      <td>Wien_9066_3_1</td>\n",
       "      <td>Wien_9066_3</td>\n",
       "      <td>Wien_9066</td>\n",
       "      <td>31701</td>\n",
       "      <td>90301</td>\n",
       "      <td>31701</td>\n",
       "      <td>AM_Rush</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4.250415e+03</td>\n",
       "      <td>8.251874</td>\n",
       "      <td>13.787251</td>\n",
       "      <td>6.937562</td>\n",
       "      <td>135.293102</td>\n",
       "      <td>0.038474</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.023820</td>\n",
       "      <td>Austria</td>\n",
       "      <td>21000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628921</th>\n",
       "      <td>Wien_10149_2_1</td>\n",
       "      <td>Wien_10149_2</td>\n",
       "      <td>Wien_10149</td>\n",
       "      <td>31711</td>\n",
       "      <td>92001</td>\n",
       "      <td>31711</td>\n",
       "      <td>AM_Rush</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.350708e+03</td>\n",
       "      <td>6.737468</td>\n",
       "      <td>10.429480</td>\n",
       "      <td>23.465284</td>\n",
       "      <td>132.376026</td>\n",
       "      <td>0.090456</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>Austria</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120123 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 HH_P_WNR          HH_PNR           HHNR Ori_geocode  \\\n",
       "0       Berlin_102956_1_1  Berlin_1029561  Berlin_102956       10115   \n",
       "1       Berlin_102956_1_2  Berlin_1029561  Berlin_102956       10115   \n",
       "2       Berlin_102964_1_1  Berlin_1029641  Berlin_102964       10115   \n",
       "3       Berlin_102964_2_1  Berlin_1029642  Berlin_102964       10115   \n",
       "10      Berlin_102966_2_1  Berlin_1029662  Berlin_102966       10115   \n",
       "...                   ...             ...            ...         ...   \n",
       "628899      Wien_6972_2_4     Wien_6972_2      Wien_6972       91101   \n",
       "628903      Wien_6972_1_1     Wien_6972_1      Wien_6972       31701   \n",
       "628904      Wien_6972_2_1     Wien_6972_2      Wien_6972       31701   \n",
       "628908      Wien_9066_3_1     Wien_9066_3      Wien_9066       31701   \n",
       "628921     Wien_10149_2_1    Wien_10149_2     Wien_10149       31711   \n",
       "\n",
       "       Des_geocode Res_geocode           Trip_Time  Season  HHSize  Sex  ...  \\\n",
       "0            10115       10115    Daytime Off-Peak  Spring     1.0    2  ...   \n",
       "1            10115       10115    Daytime Off-Peak  Spring     1.0    2  ...   \n",
       "2            10245       10115             AM_Rush  Winter     4.0    1  ...   \n",
       "3            10178       10115    Daytime Off-Peak  Winter     4.0    2  ...   \n",
       "10           10785       10115             AM_Rush  Winter     2.0    2  ...   \n",
       "...            ...         ...                 ...     ...     ...  ...  ...   \n",
       "628899       31701       31701    Daytime Off-Peak  Autumn     2.0    2  ...   \n",
       "628903       92201       31701  Nighttime Off-Peak  Autumn     2.0    1  ...   \n",
       "628904       31719       31701             AM_Rush  Autumn     2.0    2  ...   \n",
       "628908       90301       31701             AM_Rush  Autumn     4.0    2  ...   \n",
       "628921       92001       31711             AM_Rush  Autumn     3.0    1  ...   \n",
       "\n",
       "       UrbBuildDensity_res DistSubcenter_res  DistCenter_res  \\\n",
       "0             9.010181e+06          2.761334        1.972959   \n",
       "1             9.010181e+06          2.761334        1.972959   \n",
       "2             9.010181e+06          2.761334        1.972959   \n",
       "3             9.010181e+06          2.761334        1.972959   \n",
       "10            9.010181e+06          2.761334        1.972959   \n",
       "...                    ...               ...             ...   \n",
       "628899        4.250415e+03          8.251874       13.787251   \n",
       "628903        4.250415e+03          8.251874       13.787251   \n",
       "628904        4.250415e+03          8.251874       13.787251   \n",
       "628908        4.250415e+03          8.251874       13.787251   \n",
       "628921        2.350708e+03          6.737468       10.429480   \n",
       "\n",
       "        IntersecDensity_res  street_length_res  LU_UrbFab_res  \\\n",
       "0                 39.380867         127.710059       0.395459   \n",
       "1                 39.380867         127.710059       0.395459   \n",
       "2                 39.380867         127.710059       0.395459   \n",
       "3                 39.380867         127.710059       0.395459   \n",
       "10                39.380867         127.710059       0.395459   \n",
       "...                     ...                ...            ...   \n",
       "628899             6.937562         135.293102       0.038474   \n",
       "628903             6.937562         135.293102       0.038474   \n",
       "628904             6.937562         135.293102       0.038474   \n",
       "628908             6.937562         135.293102       0.038474   \n",
       "628921            23.465284         132.376026       0.090456   \n",
       "\n",
       "        bike_lane_share_res  LU_Comm_res  Country  Trip_Distance  \n",
       "0                    0.0965     0.366144  Germany          729.0  \n",
       "1                    0.0965     0.366144  Germany          729.0  \n",
       "2                    0.0965     0.366144  Germany         6259.0  \n",
       "3                    0.0965     0.366144  Germany         1474.0  \n",
       "10                   0.0965     0.366144  Germany         4455.0  \n",
       "...                     ...          ...      ...            ...  \n",
       "628899               0.0000     0.023820  Austria        25000.0  \n",
       "628903               0.0000     0.023820  Austria        25000.0  \n",
       "628904               0.0000     0.023820  Austria        20000.0  \n",
       "628908               0.0000     0.023820  Austria        21000.0  \n",
       "628921               0.0113     0.039216  Austria        25000.0  \n",
       "\n",
       "[120123 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_UF=pd.concat([df_DE,df_FR,df_Madrid,df_Wien],ignore_index=True)\n",
    "df_UF=df_UF.loc[df_UF['Trip_Purpose_Agg']=='Home↔Work',]\n",
    "df_UF.drop(columns='Trip_Purpose_Agg',inplace=True)\n",
    "\n",
    "Occ_dict={'Employed_FullTime':'Employed','Employed_PartTime':'Employed','Employed':'Employed','Trainee':'Employed',\n",
    "          'Student_School':'Student_School','Student_3rdLevel':'Student_3rdLevel','Pre-School':'Pre-School','Retired':'Retired',\n",
    "          'Unemployed':'Unemployed/Other','Other':'Unemployed/Other','Home_Partner':'Unemployed/Other'}\n",
    "Edu_dict={'University':'University','Secondary':'Secondary','Secondary+BAC':'Secondary','Secondary+Matura':'Secondary',\n",
    "          'Apprenticeship':'Apprenticeship',\n",
    "          'Elementary':'Primary/None','Pre-School':'Primary/None','No diploma yet':'Primary/None','Unknown':'Primary/None','Other':'Primary/None'}\n",
    "\n",
    "df_UF['Occupation']=df_UF['Occupation'].map(Occ_dict)\n",
    "df_UF['Education']=df_UF['Education'].map(Edu_dict)\n",
    "\n",
    "df_UF=pd.concat([df_UF.drop(columns='Trip_Distance'),df_UF['Trip_Distance']],axis=1)\n",
    "df_UF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df=df_UF.dropna()\n",
    "df['Sex']=df['Sex']-1 # change from [1,2] to [0,1], for plotting purposes\n",
    "df=df.loc[df['UrbBuildDensity_res']<1e8,]   # remove high building density outliers (For Leipzig)\n",
    "# identify the feature columns\n",
    "N_non_feature=6 # how many non-features are at the start of the df\n",
    "cols=df.columns\n",
    "newcols=(df.columns[:N_non_feature].tolist()) + ('FeatureD' +'_'+ cols[N_non_feature:-1]).tolist() + (df.columns[-1:].tolist())\n",
    "# change column names\n",
    "df.set_axis(newcols,axis=1,inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df0=df.copy()\n",
    "\n",
    "# convert  all categorical variables to dummies\n",
    "df_Cat=df.select_dtypes('object')[[col for col in df.select_dtypes('object').columns if \"FeatureD\" in col]]\n",
    "for col in df_Cat:\n",
    "    dum=pd.get_dummies(df[[col]])\n",
    "    df = pd.concat([df, dum], axis = 1)\n",
    "    # remove the original categorical columns\n",
    "df.drop(df_Cat.columns.tolist(),axis=1,inplace=True)\n",
    "# HPO with full dataset, grouping by individual person\n",
    "target = 'Trip_Distance'\n",
    "N=len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "city='All'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  columns with value below zero\n",
      "HPs already identified\n",
      "id 45596795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 54307975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 03859591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 11665252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 19378542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 30904350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 42791849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 53533809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 03543543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT Model r2: All\n",
      "0.18146066949716422\n",
      "LR Model r2: All\n",
      "0.1379503193677919\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter space to be considered\n",
    "PS = {\"learning_rate\": [0.1 ,0.15,0.2], \n",
    "                \"n_estimators\": [100, 200],\n",
    "                \"max_depth\":[3, 4]}\n",
    "\n",
    "X=df[[col for col in df.columns if \"FeatureD\" in col]]\n",
    "y = df[target]\n",
    "\n",
    "tf=(X < 0).all(0)\n",
    "print(len(tf[tf]),' columns with value below zero')\n",
    "if len(tf[tf])>0:\n",
    "    print(tf[tf].index.values)\n",
    "    raise Exception(\"Some columns have values below zero\")\n",
    "\n",
    "gr=df['HH_PNR']\n",
    "groups=gr\n",
    "gkf = list(GroupKFold(n_splits=9).split(X,y,groups)) # i found somewhere online that i had to define the cv splitter as a list, can't find the source at the moment.\n",
    "\n",
    "fp='../outputs/ML_Results/'+city+'_HPO_dist_commute_summary.csv'\n",
    "if os.path.isfile(fp):\n",
    "    print('HPs already identified')\n",
    "    HPO_summary=pd.read_csv(fp)\n",
    "    n_parameter_all = HPO_summary['N_est'][0]\n",
    "    lr_parameter_all = HPO_summary['LR'][0]\n",
    "    md_parameter_all = HPO_summary['MD'][0]\n",
    "else:\n",
    "    # define grid search cross validator\n",
    "    tuning_all = GridSearchCV(estimator=XGBRegressor(verbosity=0,use_label_encoder=False), param_grid=PS, cv=gkf, scoring=\"r2\",return_train_score=True)\n",
    "    tuning_all.fit(X,y)\n",
    "\n",
    "    print('best hyper-parameters identified by HPO')\n",
    "    print(tuning_all.best_params_)\n",
    "    print('model score with best hyper-paramteres')\n",
    "    print(tuning_all.best_score_)\n",
    "    cv_res_all=tuning_all.cv_results_\n",
    "\n",
    "    n_parameter_all = tuning_all.best_params_['n_estimators']\n",
    "    lr_parameter_all = tuning_all.best_params_['learning_rate']\n",
    "    md_parameter_all = tuning_all.best_params_['max_depth']\n",
    "\n",
    "    # save results of HPO\n",
    "    r8=['gkf_gridSearch','full','9splits_hhperGroups',tuning_all.best_params_['learning_rate'],tuning_all.best_params_['max_depth'],tuning_all.best_params_['n_estimators'],round(tuning_all.best_score_,3),round(cv_res_all['std_test_score'][tuning_all.best_index_],3),N] #\n",
    "    # also include other results lists here if HPO is done for more than one cv type or sample\n",
    "    HPO_summary=pd.DataFrame([r8],columns=['CV_Type','Sample','CV_params','LR','MD','N_est','F1_best','SD_best','N_obs']) # the last element in this case is the sd of f1 scores in the fold which produced best results\n",
    "\n",
    "# now redo the CV and calculate the SHAP values with the best HPs\n",
    "cv = GroupKFold(n_splits=9)\n",
    "\n",
    "y_predict = pd.DataFrame()\n",
    "y_predict2 = pd.DataFrame()\n",
    "y_test = pd.DataFrame()\n",
    "y_test2 = pd.DataFrame()\n",
    "\n",
    "shap_values = pd.DataFrame()\n",
    "\n",
    "r2ml=[]\n",
    "r2lr=[]\n",
    "summ_table_list=[]\n",
    "\n",
    "model = XGBRegressor(\n",
    "    max_depth=md_parameter_all, \n",
    "    n_estimators=n_parameter_all, \n",
    "    learning_rate=lr_parameter_all)\n",
    "\n",
    "writer = pd.ExcelWriter('../outputs/ML_Results/dist_commute/'  + city + '.xlsx', engine='openpyxl')\n",
    "form_str=\"Trip_Distance ~  FeatureD_HHSize + FeatureD_Sex + FeatureD_Education + FeatureD_Age + FeatureD_Season +  FeatureD_DistSubcenter_res + FeatureD_DistCenter_res + FeatureD_UrbPopDensity_res + FeatureD_UrbBuildDensity_res  + FeatureD_IntersecDensity_res + FeatureD_street_length_res + FeatureD_LU_Comm_res +  FeatureD_LU_UrbFab_res + FeatureD_bike_lane_share_res + FeatureD_Country\"\n",
    "\n",
    "for train_idx, test_idx in cv.split(X,groups=gr): # select here \n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test_fold = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    df_train, df_test = df0.iloc[train_idx], df0.iloc[test_idx]\n",
    "    y_test_fold2=df_test['Trip_Distance']\n",
    "    id=datetime.now().strftime(\"%S%f\")\n",
    "    print('id',id)\n",
    "\n",
    "    # train & predict\n",
    "    model.fit(X_train, y_train, verbose=False, eval_set=[(X_train, y_train), (X_test, y_test_fold)])\n",
    "    y_predict_fold = pd.Series(model.predict(X_test), index=X_test.index)\n",
    "    r2ml.extend([metrics.r2_score(y_test_fold.array, y_predict_fold.array)])\n",
    "    # explain\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    \n",
    "    shap_values_fold = explainer.shap_values(X_test,check_additivity=False)\n",
    "    \n",
    "    shap_values_fold = pd.DataFrame(shap_values_fold, index=X_test.index, columns=X.columns) \n",
    "\n",
    "    y_predict = pd.concat([y_predict, y_predict_fold], axis=0)\n",
    "    y_test = pd.concat([y_test, y_test_fold], axis=0)\n",
    "\n",
    "    shap_values = pd.concat([shap_values, shap_values_fold], axis=0)\n",
    "    \n",
    "    lin_reg = smf.ols(form_str, data=df_train).fit()\n",
    "    yhat=np.asarray(lin_reg.predict(df_test.drop(columns='Trip_Distance')))\n",
    "    y_predict_fold2 = pd.Series(yhat, index=df_test.index)\n",
    "    y_predict2 = pd.concat([y_predict2, y_predict_fold2], axis=0)\n",
    "    y_test2 = pd.concat([y_test2, y_test_fold2], axis=0)\n",
    "    \n",
    "    r2lr.extend([metrics.r2_score(y_test_fold.array, y_predict_fold2.array)])\n",
    "\n",
    "    coeff=lin_reg.params.reset_index()\n",
    "    coeff.rename(columns={'index':'param',0:'coefficient'},inplace=True)\n",
    "\n",
    "    pval=lin_reg.pvalues.reset_index()\n",
    "    pval.rename(columns={'index':'param',0:'p'},inplace=True)\n",
    "\n",
    "    summ_table=pd.concat([coeff,pval['p']],axis=1)\n",
    "    summ_table['param']=summ_table['param'].str.replace('FeatureD_','')\n",
    "\n",
    "    st_list_fold=[summ_table.drop(columns='param').to_numpy()]\n",
    "    summ_table_list.append(st_list_fold)\n",
    "\n",
    "    summ_table.to_excel(writer, sheet_name='summ' + id,index=False)\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()\n",
    "writer.close()\n",
    "\n",
    "mdarray=np.array(summ_table_list).squeeze()\n",
    "means=np.nanmean(mdarray,axis=0)\n",
    "means_df=pd.DataFrame(data=np.hstack((np.reshape(summ_table['param'].to_numpy(),(len(summ_table),1)),means)),columns=summ_table.columns.values)\n",
    "means_df.to_csv('../outputs/ML_Results/dist_commute/'  + city + '_mean.csv',index=False)\n",
    "\n",
    "y_test = y_test.squeeze(axis=1)\n",
    "y_test2 = y_test2.squeeze(axis=1)\n",
    "y_predict = y_predict.squeeze(axis=1)\n",
    "y_predict2 = y_predict2.squeeze(axis=1)\n",
    "r2_model=metrics.r2_score(y_test, y_predict)\n",
    "r2_model_reg=metrics.r2_score(y_test2, y_predict2)\n",
    "print('GBDT Model r2: ' + city)\n",
    "print(r2_model)\n",
    "print('LR Model r2: ' + city)\n",
    "print(r2_model_reg)\n",
    "HPO_summary['R2_full_ML']=r2_model\n",
    "HPO_summary['R2_full_LR']=r2_model_reg\n",
    "HPO_summary['City']=city\n",
    "HPO_summary.to_csv('../outputs/ML_Results/' + city + '_HPO_dist_commute_summary.csv',index=False)\n",
    "\n",
    "X_disp=[re.sub('FeatureD_','', x) for x in X.columns]\n",
    "\n",
    "shap_values=shap_values.sort_index()\n",
    "shap_values.reset_index(inplace=True)\n",
    "shap_values=shap_values.groupby('index').mean().reset_index()\n",
    "shap_values.drop(columns=['index'],inplace=True)\n",
    "\n",
    "shap.summary_plot(shap_values.sort_index().to_numpy(), X.sort_index(),feature_names=X_disp,max_display=14,show=False)\n",
    "plt.title('Feature Influence for Trip Distance, ' + city + ', R2: ' + round(r2_model,3).astype(str))\n",
    "plt.xlabel(\"SHAP value (impact on distance, in m)\")\n",
    "plt.savefig('../outputs/ML_Results/result_figures/dist_commute/' + city + '_FI_distance.png',facecolor='w',dpi=65,bbox_inches='tight')\n",
    "plt.close()\n",
    "shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "importance_df = pd.DataFrame([X_disp, shap_sum.tolist()]).T\n",
    "importance_df.columns = ['column_name', 'shap_importance']\n",
    "importance_df = importance_df.sort_values('shap_importance', ascending=False)\n",
    "\n",
    "n=importance_df[:10].index\n",
    "\n",
    "X.sort_index(inplace=True)\n",
    "data=X.sort_index().iloc[:,n]\n",
    "values=shap_values.sort_index().iloc[:,n]\n",
    "\n",
    "xl=[]\n",
    "yl=[]\n",
    "y0=[]\n",
    "\n",
    "for i in range(len(n)):\n",
    "        dftemp=pd.DataFrame({'d':data.iloc[:,i],'v':values.iloc[:,i]})\n",
    "        dftemp=dftemp.groupby('d')['v'].mean().reset_index()\n",
    "        dftemp['v0']=0\n",
    "        xl.append(dftemp['d'].values)\n",
    "        yl.append(dftemp['v'].values)\n",
    "        y0.append(dftemp['v0'].values)\n",
    "\n",
    "fig = plt.figure(figsize=(12,15))\n",
    "\n",
    "for i in range(0,8):\n",
    "        ax1 = fig.add_subplot(421+i)\n",
    "        xs=data.iloc[:,i]\n",
    "        ys=values.iloc[:,i]\n",
    "        x=xl[i]\n",
    "        y1=y0[i]\n",
    "        y2=yl[i]\n",
    "        xlab=data.columns[i]\n",
    "\n",
    "        ax1.scatter(xs,ys,alpha=0.9,s=8)\n",
    "        plt.plot(x,y1,'k:',label='zero')\n",
    "        #plt.plot(x,y2,'k',label='mean')\n",
    "        plt.legend(loc=\"upper left\",prop={'size':12})\n",
    "        if i%2==0:\n",
    "                ax1.set_ylabel('SHAP value (m)',size=13)\n",
    "        else:\n",
    "                ax1.set_ylabel('')\n",
    "        ax1.set_xlabel(xlab,size=13)\n",
    "\n",
    "        ax2 = ax1.twinx() \n",
    "        if len(xs.unique())==2:\n",
    "                ax2.hist(xs,bins=[-0.5,0.5,1.5], align='mid',color='gray',alpha=0.25)\n",
    "                ax2.set_xticks([-.5,0,0.5,1,1.5])\n",
    "        else:\n",
    "                ax2.hist(xs,bins=30,color='gray',alpha=0.15)\n",
    "                ax2.set_ylim(0,len(data))\n",
    "        ax2.set_yticks([])\n",
    "plt.suptitle(\"SHAP values for most important UF features, \" + city,y=0.92,size=16)\n",
    "plt.savefig('../outputs/ML_Results/result_figures/dist_commute/' + city + '_main.png',facecolor='w',dpi=65,bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# save shap_values, to enable later re-creation and editing of shap plots\n",
    "with open('../outputs/ML_Results/shap/dist_commute/' + city + '.pkl', 'wb') as f:\n",
    "        pickle.dump(shap_values, f)\n",
    "\n",
    "with open('../outputs/ML_Results/shap/dist_commute/' + city + '_importance.pkl', 'wb') as g:\n",
    "        pickle.dump(importance_df, g)\n",
    "\n",
    "with open('../outputs/ML_Results/shap/dist_agg/' + city + '_df.pkl', 'wb') as h:\n",
    "    pickle.dump(df, h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "city_mob_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
