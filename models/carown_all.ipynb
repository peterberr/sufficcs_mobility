{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    }
   ],
   "source": [
    "# load in required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shap\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, cross_validate, GroupKFold, StratifiedGroupKFold, RepeatedKFold, StratifiedKFold, GridSearchCV, KFold\n",
    "from sklearn import metrics, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "cities_all=['Berlin','Dresden','D端sseldorf','Frankfurt am Main','Kassel','Leipzig','Magdeburg','Potsdam','Clermont','Dijon','Lille','Lyon','Montpellier','Nantes','Nimes','Paris','Toulouse','Madrid','Wien','France_other','Germany_other']\n",
    "countries=['Germany','Germany','Germany','Germany','Germany','Germany','Germany','Germany','France','France','France','France','France','France','France','France','France','Spain','Austria','France','Germany']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dresden\n",
      "Dresden added.\n",
      "19437 rows in the combined dataframe\n",
      "Leipzig\n",
      "Leipzig added.\n",
      "21207 rows in the combined dataframe\n",
      "Magdeburg\n",
      "Magdeburg added.\n",
      "22642 rows in the combined dataframe\n",
      "Potsdam\n",
      "Potsdam added.\n",
      "23546 rows in the combined dataframe\n",
      "Frankfurt am Main\n",
      "Frankfurt am Main added.\n",
      "24442 rows in the combined dataframe\n",
      "D端sseldorf\n",
      "D端sseldorf added.\n",
      "28077 rows in the combined dataframe\n",
      "Kassel\n",
      "Kassel added.\n",
      "29417 rows in the combined dataframe\n"
     ]
    }
   ],
   "source": [
    "city0='Berlin'\n",
    "df0=pd.read_csv('../outputs/Combined/' + city0 + '_co_UF.csv')\n",
    "df0['City']=city0\n",
    "df_all=df0.copy()\n",
    "\n",
    "cities0=['Dresden','Leipzig','Magdeburg','Potsdam','Frankfurt am Main','D端sseldorf','Kassel']\n",
    "for city1 in cities0:\n",
    "    print(city1)\n",
    "    df1=pd.read_csv('../outputs/Combined/' + city1 + '_co_UF.csv')\n",
    "    #print(len(df1.columns), 'columns in the data for ', city1)\n",
    "    df1['City']=city1\n",
    "    if len(df1.columns==df_all.columns):\n",
    "        df_all=pd.concat([df_all,df1])\n",
    "        print(city1, 'added.')\n",
    "        print(len(df_all), 'rows in the combined dataframe')\n",
    "df_all['HHNR']=df_all['City']+'_'+df_all['HHNR'].astype(int).astype(str)\n",
    "\n",
    "df_DE=df_all.copy()\n",
    "df_DE['Country']='Germany'\n",
    "df_DE=df_DE.loc[:,( 'HHNR','Res_geocode',#'Dist_group', # IDs, trip geocodes, home-Res_geocode\n",
    "'HHSize','IncomeDetailed_Numeric','HHType_simp','maxAgeHH',# household details, omit  'IncomeDetailed', 'HHType', \n",
    "'UniversityEducation', 'InEmployment', 'AllRetired', # personal-based details\n",
    "'UrbPopDensity', 'UrbBuildDensity','DistSubcenter', 'DistCenter', 'transit_accessibility',\n",
    "'bike_lane_share', 'IntersecDensity', 'street_length', 'LU_UrbFab', 'LU_Comm', 'Country',\n",
    "# target: car ownership\n",
    "'CarOwnershipHH')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toulouse\n",
      "Toulouse added.\n",
      "6897 rows in the combined dataframe\n"
     ]
    }
   ],
   "source": [
    "city0='Clermont'\n",
    "df0=pd.read_csv('../outputs/Combined/' + city0 + '_co_UF.csv')\n",
    "df0['City']=city0\n",
    "df_all=df0.copy()\n",
    "\n",
    "cities0=['Toulouse']\n",
    "for city1 in cities0:\n",
    "    print(city1)\n",
    "    df1=pd.read_csv('../outputs/Combined/' + city1 + '_co_UF.csv')\n",
    "    #print(len(df1.columns), 'columns in the data for ', city1)\n",
    "    df1['City']=city1\n",
    "    if len(df1.columns==df_all.columns):\n",
    "        df_all=pd.concat([df_all,df1])\n",
    "        print(city1, 'added.')\n",
    "        print(len(df_all), 'rows in the combined dataframe')\n",
    "df_all['HHNR']=df_all['City']+'_'+df_all['HHNR'].astype(int).astype(str)\n",
    "\n",
    "df_FR=df_all.copy()\n",
    "df_FR['Country']='France'\n",
    "df_FR=df_FR.loc[:,( 'HHNR','Res_geocode',#'Dist_group', # IDs, trip geocodes, home-Res_geocode\n",
    "'HHSize','IncomeDetailed_Numeric','HHType_simp','maxAgeHH',# household details, omit  'IncomeDetailed', 'HHType', \n",
    "'UniversityEducation', 'InEmployment', 'AllRetired', # personal-based details\n",
    "'UrbPopDensity', 'UrbBuildDensity','DistSubcenter', 'DistCenter', 'transit_accessibility',\n",
    "'bike_lane_share', 'IntersecDensity', 'street_length', 'LU_UrbFab', 'LU_Comm', 'Country',\n",
    "# target: car ownership\n",
    "'CarOwnershipHH')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "city0='Paris'\n",
    "df0=pd.read_csv('../outputs/Combined/' + city0 + '_co_UF.csv')\n",
    "df0['City']=city0\n",
    "df_Paris=df0.copy()\n",
    "df_Paris['Country']='France'\n",
    "\n",
    "df_Paris=df_Paris.loc[:,( 'HHNR','Res_geocode',#'Dist_group', # IDs, trip geocodes, home-Res_geocode\n",
    "'HHSize','IncomeDetailed_Numeric','HHType_simp','maxAgeHH',# household details, omit  'IncomeDetailed', 'HHType', \n",
    "'UniversityEducation', 'InEmployment', 'AllRetired', # personal-based details\n",
    "'UrbPopDensity', 'UrbBuildDensity','DistSubcenter', 'DistCenter', 'transit_accessibility',\n",
    "'bike_lane_share', 'IntersecDensity', 'street_length', 'LU_UrbFab', 'LU_Comm', 'Country',\n",
    "# target: car ownership\n",
    "'CarOwnershipHH')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df_DE,df_FR,df_Paris],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "city='All'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  columns with value below zero\n",
      "HPs already identified\n",
      "id 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:13:45] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.471307\n",
      "         Iterations 6\n",
      "id 4\n",
      "[14:13:47] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.472035\n",
      "         Iterations 6\n",
      "id 3\n",
      "[14:13:48] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.469514\n",
      "         Iterations 6\n",
      "id 6\n",
      "[14:13:50] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.474057\n",
      "         Iterations 6\n",
      "id 1\n",
      "[14:13:51] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.472263\n",
      "         Iterations 6\n",
      "id 13\n",
      "[14:13:53] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.469101\n",
      "         Iterations 6\n",
      "id 5\n",
      "[14:13:55] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.470088\n",
      "         Iterations 6\n",
      "id 0\n",
      "[14:13:56] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.470672\n",
      "         Iterations 6\n",
      "id 10\n",
      "[14:13:59] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.468911\n",
      "         Iterations 6\n",
      "Model f1, ML: All\n",
      "0.783096823587907\n",
      "Model f1, LR: All\n",
      "0.7564514097084405\n"
     ]
    }
   ],
   "source": [
    "df.loc[df['HHType_simp'].isin(['Single_Female_Parent','Single_Male_Parent']),'HHType_simp']='Single_Parent'\n",
    "df=df.loc[df['UrbPopDensity']<80000,]   \n",
    "# remove high building density outliers (For Leipzig)\n",
    "df=df.loc[df['UrbBuildDensity']<1e8,]   \n",
    "df=df.loc[df['maxAgeHH']>0,]  \n",
    "df.dropna(inplace=True)\n",
    "df.drop(columns='UrbBuildDensity',inplace=True)\n",
    "df.drop(columns='HHType_simp',inplace=True)\n",
    "\n",
    "# identify the feature columns\n",
    "N_non_feature=2 # how many non-features are at the start of the df\n",
    "cols=df.columns\n",
    "newcols=(df.columns[:N_non_feature].tolist()) + ('FeatureO' +'_'+ cols[N_non_feature:-1]).tolist() + (df.columns[-1:].tolist())\n",
    "# change column names\n",
    "df.set_axis(newcols,axis=1,inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df0=df.copy()\n",
    "\n",
    "# convert  all categorical variables to dummies\n",
    "df_Cat=df.select_dtypes('object')[[col for col in df.select_dtypes('object').columns if \"FeatureO\" in col]]\n",
    "for col in df_Cat:\n",
    "    dum=pd.get_dummies(df[[col]])\n",
    "    df = pd.concat([df, dum], axis = 1)\n",
    "    # remove the original categorical columns\n",
    "df.drop(df_Cat.columns.tolist(),axis=1,inplace=True)\n",
    "# HPO with full dataset, grouping by individual person\n",
    "target = 'CarOwnershipHH'\n",
    "N=len(df)\n",
    "# Define the parameter space to be considered\n",
    "PS = {\"learning_rate\": [0.1 ,0.15,0.2,0.3], \n",
    "                \"n_estimators\": [100, 200, 300, 400],\n",
    "                \"max_depth\":[4, 5]}\n",
    "\n",
    "X=df[[col for col in df.columns if \"FeatureO\" in col]]\n",
    "y = df[target]\n",
    "\n",
    "tf=(X < 0).all(0)\n",
    "print(len(tf[tf]),' columns with value below zero')\n",
    "if len(tf[tf])>0:\n",
    "    print(tf[tf].index.values)\n",
    "    raise Exception(\"Some columns have values below zero\")\n",
    "\n",
    "kf = list(KFold(n_splits=9,shuffle=True).split(X,y))\n",
    "\n",
    "# define grid search cross validator\n",
    "# if not already done!! #\n",
    "# if file '../ML_Results/' + city + '_HPO_carown_summary.csv' does not exist, run the HPO and create it. \n",
    "# other wise pd.read_csv the file and extract variables ['LR','MD','N']\n",
    "fp='../outputs/ML_Results/'+city+'_HPO_carown_summary.csv'\n",
    "if os.path.isfile(fp):\n",
    "    print('HPs already identified')\n",
    "    HPO_summary=pd.read_csv(fp)\n",
    "    n_parameter_all = HPO_summary['N'][0]\n",
    "    lr_parameter_all = HPO_summary['LR'][0]\n",
    "    md_parameter_all = HPO_summary['MD'][0]\n",
    "else:\n",
    "    tuning_all = GridSearchCV(estimator=XGBClassifier(verbosity=0,use_label_encoder=False), param_grid=PS, cv=kf, scoring=\"f1_weighted\",return_train_score=True)\n",
    "    tuning_all.fit(X,y)\n",
    "\n",
    "    print('best hyper-parameters identified by HPO')\n",
    "    print(tuning_all.best_params_)\n",
    "    print('model score with best hyper-paramteres')\n",
    "    print(tuning_all.best_score_)\n",
    "    cv_res_all=tuning_all.cv_results_\n",
    "\n",
    "    n_parameter_all = tuning_all.best_params_['n_estimators']\n",
    "    lr_parameter_all = tuning_all.best_params_['learning_rate']\n",
    "    md_parameter_all = tuning_all.best_params_['max_depth']\n",
    "\n",
    "    # save results of HPO\n",
    "    r8=['kf_gridSearch','full','9splits',tuning_all.best_params_['learning_rate'],tuning_all.best_params_['max_depth'],tuning_all.best_params_['n_estimators'],round(tuning_all.best_score_,3),round(cv_res_all['std_test_score'][tuning_all.best_index_],3),N] #\n",
    "\n",
    "    # also include other results lists here if HPO is done for more than one cv type or sample\n",
    "    HPO_summary=pd.DataFrame([r8],columns=['CV_Type','Sample','CV_params','LR','MD','N','F1_best','SD_best','N_obs']) # the last element in this case is the sd of f1 scores in the fold which produced best results\n",
    "\n",
    "# now redo the CV and calculate the SHAP values with the best HPs\n",
    "cv = KFold(n_splits=9,shuffle=True)\n",
    "\n",
    "y_predict = pd.DataFrame()\n",
    "y_predict2 = pd.DataFrame()\n",
    "y_test = pd.DataFrame()\n",
    "y_test2 = pd.DataFrame()\n",
    "\n",
    "summ_table_list=[]\n",
    "\n",
    "shap_values= pd.DataFrame()\n",
    "\n",
    "model = XGBClassifier(\n",
    "    max_depth=md_parameter_all, \n",
    "    n_estimators=n_parameter_all, \n",
    "    learning_rate=lr_parameter_all)\n",
    "\n",
    "#form_str=\"CarOwnershipHH ~ FeatureO_HHSize + FeatureO_IncomeDetailed_Numeric + FeatureO_HHType_simp + FeatureO_maxAgeHH  + FeatureO_UniversityEducation + FeatureO_InEmployment + FeatureO_AllRetired + FeatureO_UrbPopDensity +  FeatureO_UrbBuildDensity  + FeatureO_DistSubcenter +  FeatureO_DistCenter + FeatureO_bike_lane_share + FeatureO_IntersecDensity +  FeatureO_street_length +  FeatureO_LU_UrbFab +  FeatureO_LU_Comm + FeatureO_transit_accessibility + FeatureO_Country\"\n",
    "#form_str=\"CarOwnershipHH ~ FeatureO_HHSize + FeatureO_IncomeDetailed_Numeric + FeatureO_HHType_simp + FeatureO_maxAgeHH  + FeatureO_UniversityEducation + FeatureO_InEmployment + FeatureO_AllRetired + FeatureO_UrbPopDensity + FeatureO_DistSubcenter +  FeatureO_DistCenter + FeatureO_bike_lane_share + FeatureO_IntersecDensity +  FeatureO_street_length +  FeatureO_LU_UrbFab +  FeatureO_LU_Comm + FeatureO_transit_accessibility + FeatureO_Country\"\n",
    "form_str=\"CarOwnershipHH ~ FeatureO_HHSize + FeatureO_IncomeDetailed_Numeric + FeatureO_maxAgeHH  + FeatureO_UniversityEducation + FeatureO_InEmployment + FeatureO_AllRetired + FeatureO_UrbPopDensity + FeatureO_DistSubcenter +  FeatureO_DistCenter + FeatureO_bike_lane_share + FeatureO_IntersecDensity +  FeatureO_street_length +  FeatureO_LU_UrbFab +  FeatureO_LU_Comm + FeatureO_transit_accessibility + FeatureO_Country\"\n",
    "writer = pd.ExcelWriter('../outputs/ML_Results/carown_LR_new/'  + city + '.xlsx', engine='openpyxl')\n",
    "for train_idx, test_idx in cv.split(X): # select here \n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test_fold = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    df_train, df_test = df0.iloc[train_idx], df0.iloc[test_idx]\n",
    "    id=test_idx[0].astype(str)\n",
    "    print('id',id)\n",
    "    y_test_fold2=df_test['CarOwnershipHH']\n",
    "\n",
    "    # train & predict\n",
    "    model.fit(X_train, y_train, verbose=False, eval_set=[(X_train, y_train), (X_test, y_test_fold)])\n",
    "    y_predict_fold = pd.Series(model.predict(X_test), index=X_test.index)\n",
    "\n",
    "    # explain\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values_fold = explainer.shap_values(X_test)\n",
    "\n",
    "    shap_values_fold = pd.DataFrame(shap_values_fold, index=X_test.index, columns=X.columns)     \n",
    "\n",
    "    y_predict = pd.concat([y_predict, y_predict_fold], axis=0)\n",
    "    y_test = pd.concat([y_test, y_test_fold], axis=0)\n",
    "\n",
    "    shap_values = pd.concat([shap_values, shap_values_fold], axis=0)\n",
    "\n",
    "    try:\n",
    "        log_reg = smf.logit(form_str, data=df_train).fit()\n",
    "        yhat=np.asarray(round(log_reg.predict(df_test.drop(columns='CarOwnershipHH'))))\n",
    "        y_predict_fold2 = pd.Series(yhat, index=df_test.index)\n",
    "        y_predict2 = pd.concat([y_predict2, y_predict_fold2], axis=0)\n",
    "        y_test2 = pd.concat([y_test2, y_test_fold2], axis=0)\n",
    "\n",
    "        coeff=log_reg.params.reset_index()\n",
    "        coeff.rename(columns={'index':'param',0:'coefficient'},inplace=True)\n",
    "\n",
    "        pval=log_reg.pvalues.reset_index()\n",
    "        pval.rename(columns={'index':'param',0:'p'},inplace=True)\n",
    "\n",
    "        summ_table=pd.concat([coeff,pval['p']],axis=1)\n",
    "        summ_table['param']=summ_table['param'].str.replace('FeatureO_','')\n",
    "\n",
    "        st_list_fold=[summ_table.drop(columns='param').to_numpy()]\n",
    "        summ_table_list.append(st_list_fold)\n",
    "\n",
    "        summ_table.to_excel(writer, sheet_name='summ' + id,index=False)\n",
    "    except Exception as err:\n",
    "        print('Logit Model Error')\n",
    "        print(type(err))\n",
    "        print(err)\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()\n",
    "writer.close()\n",
    "\n",
    "mdarray=np.array(summ_table_list).squeeze()\n",
    "means=np.nanmean(mdarray,axis=0)\n",
    "means_df=pd.DataFrame(data=np.hstack((np.reshape(summ_table['param'].to_numpy(),(len(summ_table),1)),means)),columns=summ_table.columns.values)\n",
    "means_df.to_csv('../outputs/ML_Results/carown_LR_new/'  + city + '_mean.csv',index=False)\n",
    "\n",
    "y_test = y_test.squeeze(axis=1)\n",
    "y_test2 = y_test2.squeeze(axis=1)\n",
    "y_predict = y_predict.squeeze(axis=1)\n",
    "y_predict2 = y_predict2.squeeze(axis=1)\n",
    "f1_model_ML = metrics.f1_score(y_test, y_predict, average='weighted')\n",
    "f1_model_LR = metrics.f1_score(y_test2, y_predict2, average='weighted')\n",
    "print('Model f1, ML: ' + city)\n",
    "print(f1_model_ML)\n",
    "print('Model f1, LR: ' + city)\n",
    "print(f1_model_LR)\n",
    "\n",
    "HPO_summary['F1_full_ML']=f1_model_ML\n",
    "HPO_summary['F1_full_LR']=f1_model_LR\n",
    "HPO_summary['City']=city\n",
    "HPO_summary.to_csv('../outputs/ML_Results/' + city + '_HPO_carown_new_summary.csv',index=False)\n",
    "\n",
    "# save shap_values, to enable later re-creation and editing of shap plots\n",
    "with open('../outputs/ML_Results/shap/carown_new/' + city + '.pkl', 'wb') as f:\n",
    "    pickle.dump(shap_values, f)\n",
    "\n",
    "# optionally here, check which variables are more important than random noise, then downselect X to those variables, and go back to HPO (or CV) and run once more from there.\n",
    "X_disp=[re.sub('FeatureO_','', x) for x in X.columns]\n",
    "\n",
    "shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "importance_df = pd.DataFrame([X_disp, shap_sum.tolist()]).T\n",
    "importance_df.columns = ['column_name', 'shap_importance']\n",
    "importance_df = importance_df.sort_values('shap_importance', ascending=False)\n",
    "\n",
    "with open('../outputs/ML_Results/shap/carown_new/' + city + '_importance.pkl', 'wb') as f:\n",
    "    pickle.dump(importance_df, f)\n",
    "\n",
    "shap.summary_plot(shap_values.sort_index().to_numpy(), X.sort_index(),feature_names=X_disp,show=False)\n",
    "plt.title('Overall Feature Influence Car Ownership ' + city)\n",
    "plt.savefig('../outputs/ML_Results/result_figures/carown_new/' + city + '_FI_carown.png',facecolor='w',dpi=65,bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_predict,normalize='true')\n",
    "# note the high confusion between bike/foot trips, and the high number of transit trips labelled as bike or car, and the high number of bike trips labelled as foot or car\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix, car ownership, ' + city + '. F1: ' + str(round(f1_model_ML,3)))\n",
    "plt.savefig('../outputs/ML_Results/result_figures/carown_new/' + city + '_carown_CM.png',facecolor='w',dpi=65,bbox_inches='tight')\n",
    "plt.close() \n",
    "\n",
    "col_dict= {'DistCenter':'Dist. to city center','IntersecDensity':'Instersection density','street_length':'Avg. street length',\n",
    "            'UniversityEducation':'University education','AllRetired':'Retired','bike_lane_share':'Cycle lane share',\n",
    "    'UrbBuildDensity':'Built-up density','UrbPopDensity':'Population density', 'DistSubcenter':'Dist. to subcenter','transit_accessibility':'Transit accessibility',\n",
    "    'LU_Urban':'Urban area','LU_UrbFab':'Urban fabric area','LU_Comm':'Commercial area',\n",
    "    'IncomeDetailed_Numeric':'Income','HHSize':'Household size','maxAgeHH':'Max householder age','InEmployment':'Employed','Country_France':'France',\n",
    "    'HHType_simp_Single_Female':'Single female household','HHType_simp_MultiAdult':'Multi-adult household','HHType_simp_MultiAdult_Kids':'Multi-adult household with kids'}\n",
    "X_lab=[*map(col_dict.get, X_disp)]\n",
    "\n",
    "shap.summary_plot(shap_values.sort_index().to_numpy(), X.sort_index(),feature_names=X_lab,max_display=10,show=False)\n",
    "plt.title('Overall Feature Influence Car Ownership ' + city, size=14)\n",
    "plt.xlabel(\"SHAP (probability of car ownership)\", size=12)\n",
    "plt.savefig('../outputs/ML_Results/result_figures/carown_new/' + city + '_FI_small.png',facecolor='w',dpi=65,bbox_inches='tight')\n",
    "plt.close() \n",
    "\n",
    "n=importance_df[:10].index\n",
    "shap_values.sort_index(inplace=True)\n",
    "X.sort_index(inplace=True)\n",
    "data=X.sort_index().iloc[:,n]\n",
    "values=shap_values.sort_index().iloc[:,n]\n",
    "\n",
    "xl=[]\n",
    "yl=[]\n",
    "y0=[]\n",
    "\n",
    "for i in range(len(n)):\n",
    "    dftemp=pd.DataFrame({'d':data.iloc[:,i],'v':values.iloc[:,i]})\n",
    "    dftemp=dftemp.groupby('d')['v'].mean().reset_index()\n",
    "    dftemp['v0']=0\n",
    "    xl.append(dftemp['d'].values)\n",
    "    yl.append(dftemp['v'].values)\n",
    "    y0.append(dftemp['v0'].values)\n",
    "\n",
    "citylab=city\n",
    "if city == 'Germany_other': citylab='Germany, other'\n",
    "if city == 'France_other': citylab='France, other'\n",
    "\n",
    "lab_dict= {'DistCenter':'Dist. to city center (km)','IntersecDensity':'Instersection density','street_length':'Avg. street length','bike_lane_share':'Cycle lane share','Country_France':'France',\n",
    "    'UrbBuildDensity':'Built-up density','UrbPopDensity':'Population density', 'DistSubcenter':'Dist. to subcenter','LU_UrbFab':'Urban fabric area','LU_Urban':'Urban area','transit_accessibility':'Transit accessibility',\n",
    "    'IncomeDetailed_Numeric':'Income','HHSize':'Household size','maxAgeHH':'Max householder age','InEmployment':'Employed'}\n",
    "\n",
    "importance_df['column_label']=importance_df['column_name'].map(lab_dict)\n",
    "\n",
    "if 'FeatureO_DistCenter' in data.columns:\n",
    "    fig = plt.figure()\n",
    "    i=data.columns.get_loc('FeatureO_DistCenter')\n",
    "    ax1 = fig.add_subplot(111) \n",
    "    xs=data.iloc[:,i]\n",
    "    ys=values.iloc[:,i]\n",
    "\n",
    "    x=xl[i]\n",
    "    y1=y0[i]\n",
    "    y2=yl[i]\n",
    "    xlab=importance_df['column_label'].iloc[i]\n",
    "\n",
    "    ax1.scatter(xs+np.random.normal(0, 0.05, len(data)),ys,alpha=0.3,s=8)\n",
    "    plt.plot(x,y1,'k:',label='zero')\n",
    "    plt.plot(x,y2,'k',label='mean')\n",
    "    #plt.legend(loc=\"upper left\",prop={'size':12})\n",
    "    if i%2==0:\n",
    "        ax1.set_ylabel('SHAP value',size=13)\n",
    "    else:\n",
    "        ax1.set_ylabel('')\n",
    "    ax1.set_xlabel(xlab,size=14)\n",
    "\n",
    "\n",
    "    ax2 = ax1.twinx() \n",
    "    if len(xs.unique())==2:\n",
    "        ax2.hist(xs,bins=[-0.5,0.5,1.5], align='mid',color='gray',alpha=0.15)\n",
    "        ax2.set_xticks([-.5,0,0.5,1,1.5])\n",
    "    else:\n",
    "        ax2.hist(xs,bins=30,color='gray',alpha=0.15)\n",
    "        ax2.set_ylim(0,len(data))\n",
    "    ax2.set_yticks([])\n",
    "    \n",
    "\n",
    "    if city == 'Berlin': let='a'\n",
    "    elif city == 'Paris': let='b'\n",
    "    # elif city == 'Madrid': let='c'\n",
    "    # elif city == 'Wien': let='d'\n",
    "    elif city == 'Germany_other': let='c'\n",
    "    elif city == 'France_other': let='d'\n",
    "    else: let='0'\n",
    "\n",
    "    plt.title(let + ') ' + citylab,fontsize=16)\n",
    "    ax1.set_ylabel('SHAP (car ownership probability)',size=13)\n",
    "    plt.savefig('../outputs/ML_Results/result_figures/carown_new/' + city + '_d2c.png',facecolor='w',dpi=65,bbox_inches='tight')\n",
    "    plt.close() \n",
    "\n",
    "fig = plt.figure(figsize=(11,11))\n",
    "i=0\n",
    "for i in range(0,6):\n",
    "    ax1 = fig.add_subplot(321+i)\n",
    "    xs=data.iloc[:,i]\n",
    "    ys=values.iloc[:,i]\n",
    "    x=xl[i]\n",
    "    y1=y0[i]\n",
    "    y2=yl[i]\n",
    "    xlab=importance_df['column_label'].iloc[i]\n",
    "\n",
    "    ax1.scatter(xs+np.random.normal(0, 0.05, len(data)),ys,alpha=0.3,s=8)\n",
    "    plt.plot(x,y1,'k:',label='zero')\n",
    "    plt.plot(x,y2,'k',label='mean')\n",
    "    #plt.legend(loc=\"upper left\",prop={'size':12})\n",
    "    if i%2==0:\n",
    "        ax1.set_ylabel('SHAP (car own prob.)',size=13)\n",
    "    else:\n",
    "        ax1.set_ylabel('')\n",
    "    ax1.set_xlabel(xlab,size=13)\n",
    "\n",
    "    ax2 = ax1.twinx() \n",
    "    if len(xs.unique())==2:\n",
    "        ax2.hist(xs,bins=[-0.5,0.5,1.5], align='mid',color='gray',alpha=0.15)\n",
    "        ax2.set_xticks([-.5,0,0.5,1,1.5])\n",
    "    else:\n",
    "        ax2.hist(xs,bins=30,color='gray',alpha=0.15)\n",
    "        ax2.set_ylim(0,len(data))\n",
    "    ax2.set_yticks([])\n",
    "plt.suptitle(\"SHAP and feature values for features influencing car ownership, \" + city.replace('_',', '),y=0.92,size=16)\n",
    "plt.savefig('../outputs/ML_Results/result_figures/carown_new/' + city + '_FI_detail6.png',facecolor='w',dpi=65,bbox_inches='tight')\n",
    "plt.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "city_mob_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
